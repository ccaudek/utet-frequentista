<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>6&nbsp; Significatività statistica – Inferenza frequentista in psicologia — Modulo introduttivo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapters/frequentist_inference/06_two_ind_samples.html" rel="next">
<link href="../../chapters/frequentist_inference/04_sample_size.html" rel="prev">
<link href="../../style/gauss.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-0a72236910a44089af39cd28873f322e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-9908c7b05874059c2106d454ac00f1d0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-QT5S3P9D31"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-QT5S3P9D31', { 'anonymize_ip': true});
</script><style>html{ scroll-behavior: smooth; }</style>
<script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
</script><script>
window.MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { scale: 1, mtextInheritFont: true, fontCache: 'none', minScale: 1 },
  options: { renderActions: { addMenu: [0, '', ''] } },
  loader: { load: ['input/tex','output/svg'] }
};
// Suggerimento CSS: vedi sezione 3 per gli spazi attorno a display math
</script><script>
window.MathJax = {
  tex: {
    packages: {'[+]': ['boldsymbol']},
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: { fontCache: 'global' }
};
</script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../../style/_typography-extras.css">
<link rel="stylesheet" href="../../style/_code-extras.css">
<link rel="stylesheet" href="../../style/_math-extras.css">
<link rel="stylesheet" href="../../style/styles.css">
</head>
<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html">Frequentismo</a></li><li class="breadcrumb-item"><a href="../../chapters/frequentist_inference/05_test_ipotesi.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">Inferenza frequentista in psicologia — Modulo introduttivo</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/utet-frequentista/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Percorso e obiettivi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prefazione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prefazione</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Frequentismo</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/01_galton.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inferenza frequentista</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/02_stime_parametri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Stime, stimatori e parametri</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/03_conf_interv.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Intervalli di fiducia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/04_sample_size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/05_test_ipotesi.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Significatività statistica</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/frequentist_inference/06_two_ind_samples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Epilogo</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapters/epiloque/epiloque.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Considerazioni Conclusive</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Sommario</h2>
   
  <ul class="collapse">
<li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">6.1</span> Introduzione</a></li>
  <li><a href="#test-del-chi-quadrato" id="toc-test-del-chi-quadrato" class="nav-link" data-scroll-target="#test-del-chi-quadrato"><span class="header-section-number">6.2</span> Test del Chi-Quadrato</a></li>
  <li><a href="#il-test-di-ipotesi" id="toc-il-test-di-ipotesi" class="nav-link" data-scroll-target="#il-test-di-ipotesi"><span class="header-section-number">6.3</span> Il Test di Ipotesi</a></li>
  <li><a href="#il-test-di-ipotesi-nel-contesto-frequentista" id="toc-il-test-di-ipotesi-nel-contesto-frequentista" class="nav-link" data-scroll-target="#il-test-di-ipotesi-nel-contesto-frequentista"><span class="header-section-number">6.4</span> Il Test di Ipotesi nel Contesto Frequentista</a></li>
  <li><a href="#applicazione-alla-media-campionaria" id="toc-applicazione-alla-media-campionaria" class="nav-link" data-scroll-target="#applicazione-alla-media-campionaria"><span class="header-section-number">6.5</span> Applicazione alla Media Campionaria</a></li>
  <li><a href="#applicazioni-pratiche" id="toc-applicazioni-pratiche" class="nav-link" data-scroll-target="#applicazioni-pratiche"><span class="header-section-number">6.6</span> Applicazioni pratiche</a></li>
  <li><a href="#ipotesi-statistiche" id="toc-ipotesi-statistiche" class="nav-link" data-scroll-target="#ipotesi-statistiche"><span class="header-section-number">6.7</span> Ipotesi statistiche</a></li>
  <li><a href="#i-passi-di-un-test-di-ipotesi" id="toc-i-passi-di-un-test-di-ipotesi" class="nav-link" data-scroll-target="#i-passi-di-un-test-di-ipotesi"><span class="header-section-number">6.8</span> I passi di un test di ipotesi</a></li>
  <li><a href="#ipotesi-alternativa" id="toc-ipotesi-alternativa" class="nav-link" data-scroll-target="#ipotesi-alternativa"><span class="header-section-number">6.9</span> Ipotesi alternativa</a></li>
  <li><a href="#valore-p" id="toc-valore-p" class="nav-link" data-scroll-target="#valore-p"><span class="header-section-number">6.10</span> Valore-p</a></li>
  <li><a href="#un-esempio-motivante" id="toc-un-esempio-motivante" class="nav-link" data-scroll-target="#un-esempio-motivante"><span class="header-section-number">6.11</span> Un esempio motivante</a></li>
  <li><a href="#ipotesi-nulla-e-ipotesi-alternativa" id="toc-ipotesi-nulla-e-ipotesi-alternativa" class="nav-link" data-scroll-target="#ipotesi-nulla-e-ipotesi-alternativa"><span class="header-section-number">6.12</span> Ipotesi nulla e ipotesi alternativa</a></li>
  <li><a href="#due-tipi-di-errori" id="toc-due-tipi-di-errori" class="nav-link" data-scroll-target="#due-tipi-di-errori"><span class="header-section-number">6.13</span> Due tipi di errori</a></li>
  <li><a href="#come-si-costruisce-un-test-di-ipotesi" id="toc-come-si-costruisce-un-test-di-ipotesi" class="nav-link" data-scroll-target="#come-si-costruisce-un-test-di-ipotesi"><span class="header-section-number">6.14</span> Come si costruisce un test di ipotesi?</a></li>
  <li><a href="#potenza-del-test" id="toc-potenza-del-test" class="nav-link" data-scroll-target="#potenza-del-test"><span class="header-section-number">6.15</span> Potenza del test</a></li>
  <li><a href="#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni" id="toc-la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni" class="nav-link" data-scroll-target="#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni"><span class="header-section-number">6.16</span> La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni</a></li>
  <li><a href="#malintesi-sul-valore-p" id="toc-malintesi-sul-valore-p" class="nav-link" data-scroll-target="#malintesi-sul-valore-p"><span class="header-section-number">6.17</span> Malintesi sul valore-p</a></li>
  <li><a href="#riflessioni-conclusive" id="toc-riflessioni-conclusive" class="nav-link" data-scroll-target="#riflessioni-conclusive"><span class="header-section-number">6.18</span> Riflessioni Conclusive</a></li>
  <li><a href="#esercizi" id="toc-esercizi" class="nav-link" data-scroll-target="#esercizi">Esercizi</a></li>
  <li><a href="#informazioni-sullambiente-di-sviluppo" id="toc-informazioni-sullambiente-di-sviluppo" class="nav-link" data-scroll-target="#informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia</a></li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/ccaudek/utet-frequentista/blob/main/chapters/frequentist_inference/05_test_ipotesi.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-frequentista/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapters/frequentist_inference/introduction_frequentist_inference.html">Frequentismo</a></li><li class="breadcrumb-item"><a href="../../chapters/frequentist_inference/05_test_ipotesi.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Significatività statistica</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Significatività statistica</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="callout callout-style-simple callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
In questo capitolo imparerai a
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>eseguire un test di ipotesi basato sull’ipotesi nulla.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prerequisiti
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Leggere il capitolo <em>Hypothesis Testing</em> di <a href="https://moderndive.com/v2/">Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition)</a>.</li>
<li>Leggere il capitolo <em>Testing Hypotheses</em> <span class="citation" data-cites="schervish2014probability">(<a href="#ref-schervish2014probability" role="doc-biblioref">Schervish &amp; DeGroot, 2014</a>)</span>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Preparazione del Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">here</span><span class="fu">::</span><span class="fu"><a href="https://here.r-lib.org/reference/here.html">here</a></span><span class="op">(</span><span class="st">"code"</span>, <span class="st">"_common.R"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load packages</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html">requireNamespace</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"pacman"</span><span class="op">)</span></span>
<span><span class="fu">pacman</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pacman/man/p_load.html">p_load</a></span><span class="op">(</span><span class="va">mice</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="introduzione" class="level2" data-number="6.1"><h2 data-number="6.1" class="anchored" data-anchor-id="introduzione">
<span class="header-section-number">6.1</span> Introduzione</h2>
<p>Il test di ipotesi è un metodo fondamentale della ricerca scientifica, utilizzato per fare inferenze sui parametri della popolazione a partire dai dati campionari. Nel contesto della psicologia, questo approccio viene frequentemente impiegato per valutare l’efficacia di interventi psicologici, confrontare teorie o approcci, analizzare l’influenza di variabili psicologiche su comportamenti e processi cognitivi, e approfondire i meccanismi alla base di fenomeni complessi come apprendimento, memoria ed emozioni.</p>
<p>In questo capitolo ci focalizzeremo sul test di ipotesi frequentista, un metodo largamente utilizzato ma non privo di limiti. È importante sottolineare che la comunità statistica sconsiglia di affidarsi esclusivamente a questo approccio come criterio decisionale per valutare la validità di un risultato sperimentale.</p>
</section><section id="test-del-chi-quadrato" class="level2" data-number="6.2"><h2 data-number="6.2" class="anchored" data-anchor-id="test-del-chi-quadrato">
<span class="header-section-number">6.2</span> Test del Chi-Quadrato</h2>
<p>Per introdurre il concetto di test di ipotesi nel contesto frequentista, iniziamo presentando uno dei test più semplici e utilizzati: il <strong>test del Chi-Quadrato</strong>. Questo test è particolarmente utile per valutare l’ipotesi di <strong>indipendenza</strong> tra due variabili categoriali organizzate in una <strong>tabella di contingenza</strong> (per ulteriori dettagli sulla struttura delle tabelle di contingenza, si veda il <span class="quarto-unresolved-ref">?sec-eda-qualitative-data</span>).</p>
<p>Una tabella di contingenza è una rappresentazione tabellare che mostra la distribuzione congiunta di due variabili categoriali. Ogni cella della tabella contiene la frequenza osservata delle combinazioni delle categorie delle due variabili. Inoltre, la tabella include i <strong>totali marginali</strong>, che rappresentano le somme delle frequenze per ciascuna riga e ciascuna colonna.</p>
<p>Il test del Chi-Quadrato si pone una domanda fondamentale: <strong>“Come apparirebbe la tabella di contingenza se le due variabili fossero indipendenti?”</strong>. In altre parole, il test verifica se esiste una relazione significativa tra le due variabili o se, al contrario, le variabili sono indipendenti l’una dall’altra.</p>
<p>Come già visto in precedenza analizzando la distribuzione di probabilità congiunta, si ha indipendenza quando le probabilità congiunte sono uguali al prodotto delle probabilità marginali. Partendo dalle proporzioni marginali, possiamo quindi calcolare i valori teorici attesi in ciascuna cella della tabella di contingenza, assumendo che le due variabili siano indipendenti.</p>
<p>Va sottolineato che l’indipendenza è una proprietà della popolazione, non del campione. Pertanto, nei dati campionari, ci aspettiamo che i valori osservati nelle celle della tabella differiscano leggermente dai valori teorici attesi, anche se nella popolazione le variabili sono realmente indipendenti. La discrepanza complessiva tra i valori osservati e quelli attesi, calcolati sotto l’ipotesi di indipendenza, può essere misurata utilizzando una statistica chiamata Chi-Quadrato (<span class="math inline">\(\chi^2\)</span>).</p>
<p>La formula della statistica Chi-Quadrato è:</p>
<p><span class="math display">\[
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} ,
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(O_i\)</span> rappresenta i valori osservati nelle celle della tabella,<br>
</li>
<li>
<span class="math inline">\(E_i\)</span> rappresenta i valori attesi nelle celle, calcolati sotto l’ipotesi di indipendenza,<br>
</li>
<li>La somma (<span class="math inline">\(\sum\)</span>) viene effettuata su tutte le celle della tabella.</li>
</ul>
<section id="interpretazione-della-statistica-chi-quadrato" class="level3" data-number="6.2.1"><h3 data-number="6.2.1" class="anchored" data-anchor-id="interpretazione-della-statistica-chi-quadrato">
<span class="header-section-number">6.2.1</span> Interpretazione della Statistica Chi-Quadrato</h3>
<p>La statistica Chi-Quadrato misura la discrepanza complessiva tra i valori osservati e quelli attesi. Se non ci fosse differenza tra i valori congiunti osservati e quelli teorici, la statistica Chi-Quadrato sarebbe pari a zero. All’aumentare della discrepanza tra valori osservati e attesi, il valore della statistica Chi-Quadrato aumenta.</p>
<p>Per valutare l’importanza della discrepanza osservata, utilizziamo la <strong>distribuzione campionaria della statistica Chi-Quadrato</strong>. Questa distribuzione descrive la probabilità di ottenere valori della statistica Chi-Quadrato sotto l’ipotesi nulla (indipendenza tra le variabili). La forma della distribuzione dipende dai gradi di libertà (<span class="math inline">\(\nu\)</span>), che si calcolano come:</p>
<p><span class="math display">\[
\nu = (n_{\text{righe}} - 1)(n_{\text{colonne}} - 1) ,
\]</span></p>
<p>dove <span class="math inline">\(n_{\text{righe}}\)</span> e <span class="math inline">\(n_{\text{colonne}}\)</span> rappresentano rispettivamente il numero di righe e colonne della tabella di contingenza.</p>
</section><section id="valutazione-dellipotesi-di-indipendenza" class="level3" data-number="6.2.2"><h3 data-number="6.2.2" class="anchored" data-anchor-id="valutazione-dellipotesi-di-indipendenza">
<span class="header-section-number">6.2.2</span> Valutazione dell’Ipotesi di Indipendenza</h3>
<p>La probabilità associata a una data discrepanza (<span class="math inline">\(\chi^2\)</span>) tra valori osservati e attesi, assumendo che l’ipotesi nulla sia vera, corrisponde all’area sotto la coda destra della distribuzione Chi-Quadrato, nell’intervallo [<span class="math inline">\(C\)</span>, <span class="math inline">\(+\infty\)</span>]. Questa probabilità è indicata come <span class="math inline">\(p\)</span>-value.</p>
<p>Se il <span class="math inline">\(p\)</span>-value è molto piccolo (tipicamente inferiore a una soglia predefinita, come 0.05), possiamo rifiutare l’ipotesi nulla e concludere che è improbabile che le due variabili siano indipendenti nella popolazione.</p>
</section><section id="riepilogo-dei-passaggi-del-test-chi-quadrato" class="level3" data-number="6.2.3"><h3 data-number="6.2.3" class="anchored" data-anchor-id="riepilogo-dei-passaggi-del-test-chi-quadrato">
<span class="header-section-number">6.2.3</span> Riepilogo dei Passaggi del Test Chi-Quadrato</h3>
<ol type="1">
<li>
<p><strong>Calcolo dei Valori Attesi</strong>: Per ogni cella, calcola <span class="math inline">\(E_i\)</span> utilizzando la formula:</p>
<p><span class="math display">\[
E_i = \frac{\text{Totale della Riga} \times \text{Totale della Colonna}}{\text{Totale Complessivo}}
\]</span></p>
</li>
<li>
<p><strong>Calcolo della Statistica Chi-Quadrato</strong>: Usa la formula:</p>
<p><span class="math display">\[
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}
\]</span></p>
</li>
<li><p><strong>Determinazione dei Gradi di Libertà</strong>: Calcola <span class="math inline">\(\nu\)</span> come <span class="math inline">\((n_{\text{righe}} - 1)(n_{\text{colonne}} - 1)\)</span>.</p></li>
<li><p><strong>Confronto con la Distribuzione Chi-Quadrato</strong>: Determina il <span class="math inline">\(p\)</span>-value associato al valore di <span class="math inline">\(\chi^2\)</span> calcolato e valuta l’ipotesi nulla.</p></li>
</ol>
<p>In conclusione, il Test Chi-Quadrato rappresenta uno strumento per verificare l’indipendenza tra due variabili categoriali. Grazie alla sua semplicità di applicazione e interpretazione, costituisce un metodo di analisi largamente utilizzato in ambito psicologico, sociale e statistico. Tuttavia, è importante prestare attenzione ai presupposti del test, come la sufficienza dei dati in ogni cella, per garantire risultati affidabili e interpretabili.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Creare la tabella di contingenza</span></span>
<span><span class="va">observed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">44</span>, <span class="fl">0</span>, <span class="fl">119</span>, </span>
<span>                              <span class="fl">55</span>, <span class="fl">68</span>, <span class="fl">0</span>, </span>
<span>                              <span class="fl">47</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>,</span>
<span>                            nrow <span class="op">=</span> <span class="fl">3</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Aggiungere i nomi di righe e colonne</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Biscoe"</span>, <span class="st">"Dream"</span>, <span class="st">"Torgersen"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Adelie"</span>, <span class="st">"Chinstrap"</span>, <span class="st">"Gentoo"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzare la tabella</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span></span>
<span><span class="co">#&gt;           Adelie Chinstrap Gentoo</span></span>
<span><span class="co">#&gt; Biscoe        44         0    119</span></span>
<span><span class="co">#&gt; Dream         55        68      0</span></span>
<span><span class="co">#&gt; Torgersen     47         0      0</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">chi_square_result</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span></span>
<span><span class="va">chi_square_result</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pearson's Chi-squared test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  observed</span></span>
<span><span class="co">#&gt; X-squared = 285, df = 4, p-value &lt;2e-16</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Svolgiamo i calcoli “a mano” usando R. Per calcolare la statistica del test del Chi-Quadrato “a mano” in R, segui questi passaggi:</p>
<p>Calcoliamo i totali per righe e colonne e il totale complessivo.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Totali marginali</span></span>
<span><span class="va">row_totals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span></span>
<span><span class="va">col_totals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">colSums</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span></span>
<span><span class="va">grand_total</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzare i totali</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"Totali marginali per righe:"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Totali marginali per righe:"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">row_totals</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Biscoe     Dream Torgersen </span></span>
<span><span class="co">#&gt;       163       123        47</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"Totali marginali per colonne:"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Totali marginali per colonne:"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">col_totals</span><span class="op">)</span></span>
<span><span class="co">#&gt;    Adelie Chinstrap    Gentoo </span></span>
<span><span class="co">#&gt;       146        68       119</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Totale complessivo:"</span>, <span class="va">grand_total</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Totale complessivo: 333"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I valori attesi si calcolano come:</p>
<p><span class="math display">\[
E_{ij} = \frac{\text{Totale riga} \times \text{Totale colonna}}{\text{Totale complessivo}} .
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo dei valori attesi</span></span>
<span><span class="va">expected</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/outer.html">outer</a></span><span class="op">(</span><span class="va">row_totals</span>, <span class="va">col_totals</span><span class="op">)</span> <span class="op">/</span> <span class="va">grand_total</span></span>
<span></span>
<span><span class="co"># Visualizzare i valori attesi</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"Valori attesi:"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Valori attesi:"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">expected</span><span class="op">)</span></span>
<span><span class="co">#&gt;           Adelie Chinstrap Gentoo</span></span>
<span><span class="co">#&gt; Biscoe      71.5      33.3   58.2</span></span>
<span><span class="co">#&gt; Dream       53.9      25.1   44.0</span></span>
<span><span class="co">#&gt; Torgersen   20.6       9.6   16.8</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La statistica Chi-Quadrato si calcola con:</p>
<p><span class="math display">\[
\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}} .
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo della statistica Chi-Quadrato</span></span>
<span><span class="va">chi_square_stat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">observed</span> <span class="op">-</span> <span class="va">expected</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">/</span> <span class="va">expected</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzare il risultato</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Statistica Chi-Quadrato:"</span>, <span class="va">chi_square_stat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Statistica Chi-Quadrato: 284.590012688092"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I gradi di libertà si calcolano come:</p>
<p><span class="math display">\[
dof = (\text{n. righe} - 1) \times (\text{n. colonne} - 1) .
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo dei gradi di libertà</span></span>
<span><span class="va">dof</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">observed</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzare i gradi di libertà</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"Gradi di libertà:"</span>, <span class="va">dof</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Gradi di libertà: 4"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Confrontiamo la statistica Chi-Quadrato con la distribuzione teorica per ottenere il p-value.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calcolo del p-value</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">chi_square_stat</span>, df <span class="op">=</span> <span class="va">dof</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Visualizzare il p-value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"p-value:"</span>, <span class="va">p_value</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "p-value: 2.28189154098739e-60"</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretazione:</strong><br>
Il valore-<span class="math inline">\(p\)</span> risulta molto piccolo, indicando che, se le variabili <em>Isola</em> e <em>Specie</em> fossero realmente indipendenti, sarebbe estremamente improbabile osservare una distribuzione delle specie di pinguini sulle tre isole così diversa da quella teoricamente attesa. In altre parole, il valore-<span class="math inline">\(p\)</span> rappresenta la probabilità di ottenere, per puro caso, una discrepanza tra i valori osservati e quelli attesi pari o superiore a quella riscontrata nei dati.</p>
<p>Poiché il valore-<span class="math inline">\(p\)</span> è estremamente basso, possiamo concludere che l’ipotesi di indipendenza tra le variabili <em>Isola</em> e <em>Specie</em> non è plausibile. Questo indica che la distribuzione delle specie di pinguini varia in relazione all’isola, ovvero che conoscendo l’isola è possibile prevedere la distribuzione delle specie. In altre parole, le variabili <em>Isola</em> e <em>Specie</em> sono associate.</p>
</section><section id="significatività-statistica-un-concetto-da-riconsiderare" class="level3" data-number="6.2.4"><h3 data-number="6.2.4" class="anchored" data-anchor-id="significatività-statistica-un-concetto-da-riconsiderare">
<span class="header-section-number">6.2.4</span> Significatività Statistica: Un Concetto da Riconsiderare</h3>
<p>Come discusso nell’esempio precedente, un risultato è considerato “statisticamente significativo” se la probabilità che sia dovuto al caso è bassa, il che suggerisce che il risultato sia stabile o reale. Al contrario, risultati “non significativi” vengono spesso etichettati come privi di valore e ignorati. Questa semplificazione, però, può portare a gravi fraintendimenti. Ad esempio:</p>
<ul>
<li>
<strong>Dipendenza dal campione</strong>: La significatività statistica è fortemente influenzata dalla dimensione del campione; risultati apparentemente “significativi” possono emergere anche da effetti molto piccoli in campioni ampi.</li>
<li>
<strong>Risultati non significativi</strong>: Un risultato non significativo non implica che l’effetto sia nullo o irrilevante.</li>
<li>
<strong>Scelte soggettive</strong>: Livelli di confidenza e test statistici differenti possono influenzare l’esito dell’analisi, portando a interpretazioni arbitrarie.</li>
</ul></section><section id="limiti-e-applicazioni-del-metodo-frequentista" class="level3" data-number="6.2.5"><h3 data-number="6.2.5" class="anchored" data-anchor-id="limiti-e-applicazioni-del-metodo-frequentista">
<span class="header-section-number">6.2.5</span> Limiti e Applicazioni del Metodo Frequentista</h3>
<p>Il problema più grave dell’approccio frequentista è che esso non sempre mantiene la “promessa” di fornire una base oggettiva per la decisione statistica. Infatti, il ricorso esclusivo alla significatività statistica conduce a risultati opposti a quelli desiderati, aumentando il rischio di pubblicare risultati non replicabili o di trascurare evidenze importanti <span class="quarto-unresolved-ref">?sec-crisis-s-m-errors</span>.</p>
<p>In alternativa, è più utile considerare il risultato osservato nel contesto scientifico più ampio, integrandolo con altre analisi. Questo approccio critico e completo consente di superare i limiti della significatività statistica e di interpretare i risultati con maggiore rigore.</p>
</section><section id="un-caso-specifico-la-media-del-campione" class="level3" data-number="6.2.6"><h3 data-number="6.2.6" class="anchored" data-anchor-id="un-caso-specifico-la-media-del-campione">
<span class="header-section-number">6.2.6</span> Un Caso Specifico: La Media del Campione</h3>
<p>Torniamo ora a esaminare il test di ipotesi all’interno del quadro frequentista, focalizzandoci sul caso di una variabile continua, diversamente dal contesto qualitativo trattato nel test del Chi-Quadrato. Per approfondire la comprensione della significatività statistica, analizzeremo in dettaglio l’utilizzo della media campionaria come stimatore della media della popolazione. Questa riflessione ci consentirà di esplorare sia i limiti che le applicazioni pratiche di tale strumento all’interno della statistica inferenziale frequentista. Attraverso questo esempio, potremo mettere in luce aspetti teorici e operativi dei test di ipotesi, nonché fornire indicazioni su come migliorare l’interpretazione dei risultati, con particolare riferimento al campo della ricerca psicologica.</p>
</section></section><section id="il-test-di-ipotesi" class="level2" data-number="6.3"><h2 data-number="6.3" class="anchored" data-anchor-id="il-test-di-ipotesi">
<span class="header-section-number">6.3</span> Il Test di Ipotesi</h2>
<p>Il test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (<span class="math inline">\(H_0\)</span>). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (<span class="math inline">\(H_1\)</span>) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.</p>
<section id="la-procedura-di-test-di-ipotesi" class="level3" data-number="6.3.1"><h3 data-number="6.3.1" class="anchored" data-anchor-id="la-procedura-di-test-di-ipotesi">
<span class="header-section-number">6.3.1</span> La procedura di Test di Ipotesi</h3>
<p>Esaminiamo in dettaglio le varie fasi della procedura del test di ipotesi di stampo frequentista.</p>
<p><strong>Passo 1:</strong> Formulare l’ipotesi nulla (<span class="math inline">\(H_0\)</span>) e l’ipotesi alternativa (<span class="math inline">\(H_1\)</span>) basandosi sulla domanda di ricerca.</p>
<p><strong>Passo 2:</strong> Stabilire un livello di significatività, α (solitamente 0.05).</p>
<p><strong>Passo 3:</strong> Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.</p>
<p><strong>Passo 4:</strong> Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.</p>
<ol type="a">
<li><p>L’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.</p></li>
<li><p>L’approccio del valore-p.&nbsp;Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.</p></li>
</ol>
<p>Confrontiamo il valore-p calcolato con il livello di significatività α:</p>
<ul>
<li>Se il valore-p &lt; α, si rifiuta l’ipotesi nulla (<span class="math inline">\(H_0\)</span>).</li>
<li>Se il valore-p ≥ α, non si rifiuta l’ipotesi nulla (<span class="math inline">\(H_0\)</span>).</li>
</ul></section></section><section id="il-test-di-ipotesi-nel-contesto-frequentista" class="level2" data-number="6.4"><h2 data-number="6.4" class="anchored" data-anchor-id="il-test-di-ipotesi-nel-contesto-frequentista">
<span class="header-section-number">6.4</span> Il Test di Ipotesi nel Contesto Frequentista</h2>
<p>Si noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.</p>
<p>L’American Statistical Association (ASA) definisce il valore-p come:</p>
<blockquote class="blockquote">
<p>the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).</p>
</blockquote>
<p>Questa definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.</p>
<p>Una distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.</p>
<p>Chiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?</p>
<p>Possiamo riformulare la definizione dell’ASA in questo modo:</p>
<blockquote class="blockquote">
<p>Il valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.</p>
</blockquote>
<p>Quindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.</p>
</section><section id="applicazione-alla-media-campionaria" class="level2" data-number="6.5"><h2 data-number="6.5" class="anchored" data-anchor-id="applicazione-alla-media-campionaria">
<span class="header-section-number">6.5</span> Applicazione alla Media Campionaria</h2>
<p>In questo capitolo ci concentreremo sull’applicazione del processo di test di ipotesi frequentista alla media campionaria. Vedremo come la media di un campione possa essere impiegata per trarre inferenze sulla media di una popolazione, analizzandone limiti e possibili utilizzi nell’ambito dell’inferenza statistica frequentista.</p>
<p>I test su uno o due campioni (one-sample e two-sample tests) hanno rappresentato le prime fondamenta dell’analisi statistica dei dati. Al giorno d’oggi, tuttavia, i nostri disegni sperimentali tendono a essere più complessi di quanto questi semplici test possano gestire. Nonostante ciò, tali test – in particolare il celebre t-test di Student – costituiscono ancora un’ottima porta d’ingresso alla modellazione statistica, poiché i principi su cui si basano sono relativamente intuitivi e consentono di familiarizzare con il processo di verifica dell’ipotesi.</p>
<p>Per comprendere meglio i valori-p e la verifica del test di ipotesi, può essere molto utile ricorrere a simulazioni. Attraverso queste ultime è possibile ricreare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati, fornendo così una prospettiva più chiara sulle implicazioni della statistica frequentista.</p>
<section id="la-distribuzione-della-media-campionaria" class="level3" data-number="6.5.1"><h3 data-number="6.5.1" class="anchored" data-anchor-id="la-distribuzione-della-media-campionaria">
<span class="header-section-number">6.5.1</span> La Distribuzione della Media Campionaria</h3>
<p>Quando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (<span class="math inline">\(\bar{X}\)</span>), che descrive la variazione di <span class="math inline">\(\bar{X}\)</span> attraverso infiniti campioni di dimensione <span class="math inline">\(n\)</span>. Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di <span class="math inline">\(\bar{X}\)</span> seguirà una distribuzione normale, con media <span class="math inline">\(\mu\)</span> (la media della popolazione) e deviazione standard <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> (dove <span class="math inline">\(\sigma\)</span> è la deviazione standard della popolazione e <span class="math inline">\(n\)</span> è la dimensione del campione).</p>
</section><section id="test-di-ipotesi-sulla-media-campionaria" class="level3" data-number="6.5.2"><h3 data-number="6.5.2" class="anchored" data-anchor-id="test-di-ipotesi-sulla-media-campionaria">
<span class="header-section-number">6.5.2</span> Test di Ipotesi sulla Media Campionaria</h3>
<p>Supponendo di conoscere <span class="math inline">\(\sigma\)</span> ma non <span class="math inline">\(\mu\)</span>, utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico <span class="math inline">\(\mu_0\)</span>, specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di <span class="math inline">\(\mu_0\)</span> come vera media della popolazione.</p>
</section><section id="calcolo-della-statistica-del-test" class="level3" data-number="6.5.3"><h3 data-number="6.5.3" class="anchored" data-anchor-id="calcolo-della-statistica-del-test">
<span class="header-section-number">6.5.3</span> Calcolo della Statistica del Test</h3>
<p>Per valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone <span class="math inline">\(\mu = \mu_0\)</span>, standardizziamo <span class="math inline">\(\bar{X}\)</span> usando la formula:</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}}
\]</span></p>
<p>Questa trasformazione produce una variabile <span class="math inline">\(Z\)</span> che segue una distribuzione normale standard <span class="math inline">\(\mathcal{N}(0, 1)\)</span>. Valori estremi di <span class="math inline">\(Z\)</span> (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con <span class="math inline">\(\mu_0\)</span>, portando al rigetto dell’ipotesi nulla.</p>
<section id="simulazione" class="level4" data-number="6.5.3.1"><h4 data-number="6.5.3.1" class="anchored" data-anchor-id="simulazione">
<span class="header-section-number">6.5.3.1</span> Simulazione</h4>
<p>Per illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che <span class="math inline">\(\mu_0 = 100\)</span>, <span class="math inline">\(\sigma = 15\)</span> e <span class="math inline">\(n = 30\)</span>. Vogliamo calcolare il valore-p per l’evento <span class="math inline">\(\bar{X} &gt; 105\)</span>.</p>
<p>La simulazione può essere eseguita come segue:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># To make the simulation reproducible</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu_0</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">15</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">30</span></span>
<span><span class="va">n_sim</span> <span class="op">&lt;-</span> <span class="fl">10000</span>  <span class="co"># Number of simulations</span></span>
<span></span>
<span><span class="co"># Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))</span></span>
<span><span class="va">sample_means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n_sim</span>, mean <span class="op">=</span> <span class="va">mu_0</span>, sd <span class="op">=</span> <span class="va">sigma</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate the p-value as the proportion of sample means &gt; 105</span></span>
<span><span class="va">p_value</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">sample_means</span> <span class="op">&gt;</span> <span class="fl">105</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Print the p-value</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p_value</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0339</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Questo script simula la distribuzione campionaria di <span class="math inline">\(\bar{X}\)</span> sotto l’ipotesi nulla che <span class="math inline">\(\mu = \mu_0\)</span> e calcola il valore-p per l’evento <span class="math inline">\(\bar{X} &gt; 105\)</span>. Il valore-p indica la probabilità di osservare un valore di <span class="math inline">\(\bar{X}\)</span> così estremo (o più estremo) se l’ipotesi nulla fosse vera.</p>
<p>Il risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore <span class="math inline">\(Z\)</span> per <span class="math inline">\(\bar{X} = 120\)</span> è calcolato come:</p>
<p><span class="math display">\[
Z = \frac{105 - 100}{15/\sqrt{30}}
\]</span></p>
<p>Possiamo usare la funzione <code>stats.norm.sf()</code> per trovare l’area sotto la curva normale standard a destra di questo valore <span class="math inline">\(Z\)</span>, che corrisponde al valore-p teorico.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the Z-score</span></span>
<span><span class="va">Z</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">105</span> <span class="op">-</span> <span class="fl">100</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">15</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">30</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">Z</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.83</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the upper tail probability</span></span>
<span><span class="va">upper_tail_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">Z</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">upper_tail_prob</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0339</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Oppure, in maniera equivalente</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the upper tail probability</span></span>
<span><span class="va">upper_tail_prob</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">105</span>, mean <span class="op">=</span> <span class="fl">100</span>, sd <span class="op">=</span> <span class="fl">15</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">30</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">upper_tail_prob</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0339</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Il calcolo teorico mostra che il valore <span class="math inline">\(Z\)</span> per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (<span class="math inline">\(\mu_0 = 100\)</span>). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile <em>se l’ipotesi nulla fosse vera</em>.</p>
</section></section></section><section id="applicazioni-pratiche" class="level2" data-number="6.6"><h2 data-number="6.6" class="anchored" data-anchor-id="applicazioni-pratiche">
<span class="header-section-number">6.6</span> Applicazioni pratiche</h2>
<p>Nella precedente discussione, abbiamo supposto <span class="math inline">\(\sigma\)</span> nota. Tuttavia, poiché di solito non conosciamo il valore di <span class="math inline">\(\sigma\)</span> nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria <span class="math inline">\(s\)</span>. Pertanto, al posto di <span class="math inline">\(\sigma\)</span>, possiamo utilizzare <span class="math inline">\(s\)</span>, ottenendo così la statistica:</p>
<p><span class="math display">\[
T = \frac{\bar{X} - \mu_0}{\frac{s}{\sqrt{n}}}.
\]</span></p>
<p>Si può dimostrare che la statistica <span class="math inline">\(T\)</span> segue una distribuzione <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-1\)</span> gradi di libertà <em>se il campione casuale è stato estratto da una popolazione normale</em>.</p>
<p>A questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica <span class="math inline">\(T\)</span> per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-1\)</span> gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.</p>
</section><section id="ipotesi-statistiche" class="level2" data-number="6.7"><h2 data-number="6.7" class="anchored" data-anchor-id="ipotesi-statistiche">
<span class="header-section-number">6.7</span> Ipotesi statistiche</h2>
<p>Esaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.</p>
<p>In particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata <em>ipotesi nulla</em> e viene rappresentata come <span class="math inline">\(H_0\)</span>. Per un parametro sconosciuto <span class="math inline">\(\theta\)</span>, l’ipotesi nulla viene formulata come:</p>
<p><span class="math display">\[
H_0: \theta \in \Theta_0 \subset \Theta,
\]</span></p>
<p>dove <span class="math inline">\(\Theta_0\)</span> è un sottoinsieme del dominio <span class="math inline">\(\Theta\)</span>, che rappresenta tutti i possibili valori del parametro <span class="math inline">\(\theta\)</span> coerenti con il modello statistico adottato. L’ipotesi nulla può essere <em>semplice</em> se <span class="math inline">\(\Theta_0\)</span> contiene un unico elemento, oppure <em>composta</em> se contiene più di un elemento.</p>
</section><section id="i-passi-di-un-test-di-ipotesi" class="level2" data-number="6.8"><h2 data-number="6.8" class="anchored" data-anchor-id="i-passi-di-un-test-di-ipotesi">
<span class="header-section-number">6.8</span> I passi di un test di ipotesi</h2>
<p>Per prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un <em>test statistico</em>. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.</p>
<p>Iniziamo formulando l’ipotesi nulla <span class="math inline">\(H_0\)</span>, che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa <span class="math inline">\(H_1\)</span> viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria <span class="math inline">\(\mathcal{G}_n(X_1, \dots, X_n)\)</span> che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.</p>
<p>Successivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica <span class="math inline">\(\mathcal{G}_n\)</span> in due insiemi disgiunti: la “regione di accettazione” <span class="math inline">\(\mathcal{A}\)</span> e la sua regione complementare, la “regione di rifiuto” <span class="math inline">\(\mathcal{R}\)</span>. La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.</p>
<p>Infine, selezioniamo un livello di significatività <span class="math inline">\(\alpha\)</span>, che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica <span class="math inline">\(\mathcal{G}_n\)</span> rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.</p>
<p>In sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.</p>
</section><section id="ipotesi-alternativa" class="level2" data-number="6.9"><h2 data-number="6.9" class="anchored" data-anchor-id="ipotesi-alternativa">
<span class="header-section-number">6.9</span> Ipotesi alternativa</h2>
<p>Durante un test di ipotesi, dopo aver definito l’ipotesi nulla <span class="math inline">\(H_0\)</span>, possono essere considerate diverse ipotesi alternative <span class="math inline">\(H_1\)</span>. Le ipotesi alternative più comuni si suddividono in tre tipi:</p>
<ol type="1">
<li>
<span class="math inline">\(H_1: \theta \neq \theta_0\)</span>,</li>
<li>
<span class="math inline">\(H_1: \theta &gt; \theta_0\)</span>,</li>
<li>
<span class="math inline">\(H_1: \theta &lt; \theta_0\)</span>.</li>
</ol>
<p>Queste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).</p>
<p>La scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> dell’ipotesi nulla <span class="math inline">\(H_0\)</span>. La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa <span class="math inline">\(H_1\)</span>. Nel caso di un test unilaterale inferiore, <span class="math inline">\(\mathcal{R}\)</span> si trova nella coda sinistra della distribuzione, nell’intervallo [<span class="math inline">\(-\infty\)</span>, <span class="math inline">\(\theta_0\)</span>]. Nel caso di un test unilaterale superiore, <span class="math inline">\(\mathcal{R}\)</span> si trova nella coda destra della distribuzione, nell’intervallo [<span class="math inline">\(\theta_0\)</span>, <span class="math inline">\(\infty\)</span>].</p>
<p>I <em>valori critici</em> sono i valori che delimitano la regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> in un test unilaterale e i valori che delimitano le regioni di rifiuto <span class="math inline">\(\mathcal{R}\)</span> in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span>.</p>
</section><section id="valore-p" class="level2" data-number="6.10"><h2 data-number="6.10" class="anchored" data-anchor-id="valore-p">
<span class="header-section-number">6.10</span> Valore-p</h2>
<p>Il valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita <em>assumendo come vera l’ipotesi nulla</em>. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.</p>
</section><section id="un-esempio-motivante" class="level2" data-number="6.11"><h2 data-number="6.11" class="anchored" data-anchor-id="un-esempio-motivante">
<span class="header-section-number">6.11</span> Un esempio motivante</h2>
<p>Per esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.</p>
<p>Dalle analisi condotte da <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.</p>
<section id="domanda-della-ricerca-e-ipotesi-statistiche" class="level3" data-number="6.11.1"><h3 data-number="6.11.1" class="anchored" data-anchor-id="domanda-della-ricerca-e-ipotesi-statistiche">
<span class="header-section-number">6.11.1</span> Domanda della ricerca e ipotesi statistiche</h3>
<p>La ricerca condotta da <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.</p>
<p>Per chiarire questo punto, consideriamo l’esperimento condotto sui bambini da <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span>. Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.</p>
<p>Poiché nei tipici esperimenti psicologici, come nel caso della ricerca di <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span>, l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:</p>
<ol type="1">
<li>Nel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a <span class="math inline">\(\mu = 0.5\)</span>, in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.</li>
<li>Se invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà <span class="math inline">\(\mu &gt; 0.5\)</span>, dove <span class="math inline">\(\mu = 0.5\)</span> rappresenta il livello di probabilità casuale.</li>
<li>Infine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa <span class="math inline">\(\mu &lt; 0.5\)</span>.</li>
</ol>
<p>Le tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span>, il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.</p>
</section><section id="domanda-della-ricerca-e-ipotesi-statistiche-1" class="level3" data-number="6.11.2"><h3 data-number="6.11.2" class="anchored" data-anchor-id="domanda-della-ricerca-e-ipotesi-statistiche-1">
<span class="header-section-number">6.11.2</span> Domanda della ricerca e ipotesi statistiche</h3>
<p>La distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.</p>
<p>I test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.</p>
</section></section><section id="ipotesi-nulla-e-ipotesi-alternativa" class="level2" data-number="6.12"><h2 data-number="6.12" class="anchored" data-anchor-id="ipotesi-nulla-e-ipotesi-alternativa">
<span class="header-section-number">6.12</span> Ipotesi nulla e ipotesi alternativa</h2>
<p>Fino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.</p>
<section id="apagogia" class="level3" data-number="6.12.1"><h3 data-number="6.12.1" class="anchored" data-anchor-id="apagogia">
<span class="header-section-number">6.12.1</span> Apagogia</h3>
<p>In linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.</p>
<p>L’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.</p>
<p>Questo modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con <span class="math inline">\(H_0\)</span>. Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: <span class="math inline">\(\mu \leq 0.5\)</span>. Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, <span class="math inline">\(\mu = 0.5\)</span> e <span class="math inline">\(\mu &lt; 0.5\)</span>), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, <span class="math inline">\(\mu &gt; 0.5\)</span>). Questo definisce, nel caso presente, un <em>test unilaterale</em>.</p>
<p>In pratica, ciò che stiamo facendo è dividere tutti i possibili valori di <span class="math inline">\(\mu\)</span> in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con <span class="math inline">\(H_1\)</span>) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).</p>
<p>Avendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.</p>
</section><section id="la-similitudine-del-processo-penale" class="level3" data-number="6.12.2"><h3 data-number="6.12.2" class="anchored" data-anchor-id="la-similitudine-del-processo-penale">
<span class="header-section-number">6.12.2</span> La similitudine del processo penale</h3>
<p>Un test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.</p>
</section></section><section id="due-tipi-di-errori" class="level2" data-number="6.13"><h2 data-number="6.13" class="anchored" data-anchor-id="due-tipi-di-errori">
<span class="header-section-number">6.13</span> Due tipi di errori</h2>
<p>Prima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada <em>anche se la moneta è equilibrata</em>. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.</p>
<p>A questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con <span class="math inline">\(\alpha\)</span>, è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con <span class="math inline">\(\beta\)</span>, è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.</p>
<p><img src="../../figures/tab_due_errori.png" class="img-fluid" style="width:68.0%"></p>
<section id="errore-di-i-tipo-la-protezione-dei-diritti-dellimputato" class="level3" data-number="6.13.1"><h3 data-number="6.13.1" class="anchored" data-anchor-id="errore-di-i-tipo-la-protezione-dei-diritti-dellimputato">
<span class="header-section-number">6.13.1</span> Errore di I tipo: la protezione dei diritti dell’imputato</h3>
<p>In precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.</p>
<p>Un test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con <span class="math inline">\(\alpha\)</span>, viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività <span class="math inline">\(\alpha\)</span> se il tasso di errore di I tipo non è più grande di <span class="math inline">\(\alpha\)</span>. Per convenzione, i ricercatori fanno uso di tre diversi livelli <span class="math inline">\(\alpha\)</span>: 0.05, 0.01 e 0.001.</p>
</section><section id="errore-di-ii-tipo-lasimmetria-del-giudizio" class="level3" data-number="6.13.2"><h3 data-number="6.13.2" class="anchored" data-anchor-id="errore-di-ii-tipo-lasimmetria-del-giudizio">
<span class="header-section-number">6.13.2</span> Errore di II tipo: l’asimmetria del giudizio</h3>
<p>Che dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con <span class="math inline">\(\beta\)</span>. Il livello d’errore <span class="math inline">\(\beta\)</span> viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero <span class="math inline">\(1-\beta\)</span>. Un test viene detto “potente” quando è caratterizzato da un piccolo valore <span class="math inline">\(\beta\)</span> pur mantenendo il livello <span class="math inline">\(\alpha\)</span> sotto una piccola soglia di probabilità prefissata.</p>
<p>Si noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello <span class="math inline">\(\alpha\)</span> sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di <span class="math inline">\(\beta\)</span>. Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (<span class="math inline">\(1 - \beta\)</span>) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.</p>
</section></section><section id="come-si-costruisce-un-test-di-ipotesi" class="level2" data-number="6.14"><h2 data-number="6.14" class="anchored" data-anchor-id="come-si-costruisce-un-test-di-ipotesi">
<span class="header-section-number">6.14</span> Come si costruisce un test di ipotesi?</h2>
<p>Ritorniamo all’esempio relativo allo studio di <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span>. In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come <span class="math inline">\(H_0: \mu \leq 0.5\)</span>. Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è <span class="math inline">\(\bar{X} = 0.56\)</span> Questo è il valore campionario rilevante per il test dell’ipotesi nulla.</p>
<p>Ingenuamente, potremmo pensare che, per decidere se <span class="math inline">\(H_0\)</span> sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore <span class="math inline">\(\pi\)</span> specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore <span class="math inline">\(\mu\)</span> ma bensì un intervallo di valori: <span class="math inline">\([0, 0.5]\)</span>. I dati campionari specificano un valore <span class="math inline">\(\bar{X} = 0.56\)</span>, ovvero un valore che non è incluso nell’intervallo specificato da <span class="math inline">\(H_0\)</span>. Questo è incoraggiante. Se invece avessimo osservato <span class="math inline">\(\bar{X} = 0.41\)</span>, per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con <span class="math inline">\(H_0\)</span> non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.</p>
<section id="la-variabilità-campionaria" class="level3" data-number="6.14.1"><h3 data-number="6.14.1" class="anchored" data-anchor-id="la-variabilità-campionaria">
<span class="header-section-number">6.14.1</span> La variabilità campionaria</h3>
<p>Nel caso dell’esperimento di <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> che stiamo discutendo, <span class="math inline">\(\bar{X}\)</span> non cade nell’intervallo specificato da <span class="math inline">\(H_0\)</span>. Sulla base del valore osservato <span class="math inline">\(\bar{X} = 0.56\)</span> possiamo dunque concludere che <span class="math inline">\(H_0\)</span> è falsa? Non così presto. Non è sufficiente trovare una differenza <span class="math inline">\(\bar{X} - \mu\)</span> nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della <em>variabilità campionaria</em>.</p>
<p>Infatti, la media <span class="math inline">\(\bar{X}\)</span> osservata in ogni singolo campione di ampiezza <span class="math inline">\(n=32\)</span> è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, <span class="math inline">\(\bar{X}\)</span> assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media <span class="math inline">\(\bar{X}\)</span> – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero <span class="math inline">\(\mu\)</span>, ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero <span class="math inline">\(\bar{X}\)</span>.</p>
<p>Risulta dunque chiaro che la nostra decisione rispetto ad <span class="math inline">\(H_0\)</span> non può essere unicamente basata sulla differenza tra <span class="math inline">\(\bar{X} - \mu\)</span>. Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza <span class="math inline">\(\bar{X} - \mu\)</span> sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare <span class="math inline">\(H_0\)</span> <em>per effetto del caso soltanto</em>. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza <span class="math inline">\(\bar{X} - \mu\)</span>.</p>
</section><section id="le-distribuzioni-delle-statistiche-test" class="level3" data-number="6.14.2"><h3 data-number="6.14.2" class="anchored" data-anchor-id="le-distribuzioni-delle-statistiche-test">
<span class="header-section-number">6.14.2</span> Le distribuzioni delle statistiche test</h3>
<p>Il metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test <span class="math inline">\(\mathcal{G}_n\)</span>, rilevante per il test di <span class="math inline">\(H_0\)</span>, <em>assumendo come vera l’ipotesi nulla</em>. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.</p>
<p>Lo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa <em>reductio ad absurdum</em>, la “presunzione di innocenza” di <span class="math inline">\(H_0\)</span> corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla <em>fino a prova contraria</em>.</p>
<p>Nell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro <span class="math inline">\(\mu\)</span> (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria <em>costruita assumento come vera</em> <span class="math inline">\(H_0\)</span>.</p>
<p>La standardizzazione di <span class="math inline">\(\bar{X}\)</span> si effettua mediante il rapporto</p>
<p><span class="math display">\[
T = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}},
\]</span></p>
<p>dove <span class="math inline">\(\bar{X}\)</span> è la media del campione (nel nostro caso, 0.56), <span class="math inline">\(s\)</span> è la deviazione standard del campione (gli autori riportano <span class="math inline">\(s\)</span> = 0.179) e <span class="math inline">\(n\)</span> è l’ampiezza del campione (ovvero, <span class="math inline">\(n\)</span> = 32). Per il caso presente otteniamo:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="cn">T</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">0.56</span> <span class="op">-</span> <span class="fl">0.50</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">0.179</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="cn">T</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.9</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="regioni-di-rifiuto-e-regioni-di-non-rifiuto" class="level3" data-number="6.14.3"><h3 data-number="6.14.3" class="anchored" data-anchor-id="regioni-di-rifiuto-e-regioni-di-non-rifiuto">
<span class="header-section-number">6.14.3</span> Regioni di rifiuto e regioni di non rifiuto</h3>
<p>Conoscendo la distribuzione dei valori della statistica test (distribuzione determinata <em>assumendo come vera</em> <span class="math inline">\(H_0\)</span>) diventa poi possibile dividere l’insieme dei valori possibili di <span class="math inline">\(\mathcal{G}_n\)</span> (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare <span class="math inline">\(H_0\)</span> (regione di rifiuto) e quelli che non ci consentono di rigettare <span class="math inline">\(H_0\)</span> (regione di non rifiuto).</p>
<p>Per decidere quanto deve essere grande la regione di rifiuto di <span class="math inline">\(H_0\)</span> è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test <span class="math inline">\(\mathcal{G}_n\)</span>, ovvero quelli che sarebbe molto improbabile osservare se <span class="math inline">\(H_0\)</span> fosse vera.</p>
</section><section id="quando-rifiutare-lipotesi-nulla" class="level3" data-number="6.14.4"><h3 data-number="6.14.4" class="anchored" data-anchor-id="quando-rifiutare-lipotesi-nulla">
<span class="header-section-number">6.14.4</span> Quando rifiutare l’ipotesi nulla</h3>
<p>Supponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test <span class="math inline">\(\mathcal{G}_n\)</span>.</p>
<p><img src="../../figures/test-ipotesi-1.png" class="img-fluid" style="width:80.0%"></p>
<p>Se i dati producono la statistica test <span class="math inline">\(\mathcal{G}_n^1\)</span>, non possiamo rifiutare l’ipotesi nulla <span class="math inline">\(H_0\)</span>. Se invece i dati producono <span class="math inline">\(\mathcal{G}_n^2\)</span> allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.</p>
<ol type="1">
<li>La regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera <span class="math inline">\(H_0\)</span>.</li>
<li>La regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.</li>
<li>In questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo <span class="math inline">\(H_0\)</span> basandoci unicamente sulla distribuzione campionaria <span class="math inline">\(f(\mathcal{G}_n \mid H_0)\)</span>, cioè sulla probabilità della statistica test condizionata all’ipotesi nulla <span class="math inline">\(H_0\)</span>. L’ipotesi alternativa <span class="math inline">\(H_1\)</span> viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di <span class="math inline">\(H_0\)</span>, ma formalmente non gioca alcun ruolo nel rigettare o meno <span class="math inline">\(H_0\)</span>.</li>
</ol></section><section id="specificazione-delle-regioni-di-rifiuto" class="level3" data-number="6.14.5"><h3 data-number="6.14.5" class="anchored" data-anchor-id="specificazione-delle-regioni-di-rifiuto">
<span class="header-section-number">6.14.5</span> Specificazione delle regioni di rifiuto</h3>
<p>L’ipotesi alternativa <span class="math inline">\(H_1\)</span> può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> di <span class="math inline">\(H_0\)</span>. La regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa <span class="math inline">\(H_1\)</span>.</p>
<ul>
<li>Se l’ipotesi alternativa è <span class="math inline">\(H_1: \theta \neq \theta_0\)</span> (dove <span class="math inline">\(\theta\)</span> è un generico parametro e <span class="math inline">\(\theta_0\)</span> è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di <span class="math inline">\(H_0\)</span>) sono contenute negli intervalli <span class="math inline">\([-\infty, \theta_0]\)</span> e <span class="math inline">\([\theta_0, +\infty]\)</span>.</li>
<li>Se l’ipotesi alternativa è <span class="math inline">\(H_1: \theta &lt; \theta_0\)</span>, allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di <span class="math inline">\(H_0\)</span>) sono contenute nell’intervallo <span class="math inline">\([-\infty, \theta_0]\)</span> e l’intera regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> è collocata nella coda di sinistra della distribuzione.</li>
<li>Se l’ipotesi alternativa è <span class="math inline">\(H_1: \theta &gt; \theta_0\)</span>, allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di <span class="math inline">\(H_0\)</span>) sono contenute nell’intervallo <span class="math inline">\([\theta_0, \infty]\)</span> e l’intera regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> è collocata nella coda di destra della distribuzione.</li>
</ul>
<p>Si chiamano <em>valori critici</em> i valori che delimitano la regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span> in un test unilaterale e i valori che delimitano le regioni di rifiuto <span class="math inline">\(\mathcal{R}\)</span> in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a <span class="math inline">\(\alpha/2\)</span>; in un test unidirezionale lasciano una probabilità pari ad <span class="math inline">\(\alpha\)</span> in una sola coda. Il risultato di un test si dice <em>statisticamente significativo</em> quando il valore della statistica test ricade nella regione di rifiuto <span class="math inline">\(\mathcal{R}\)</span>.</p>
</section><section id="la-decisione-statistica" class="level3" data-number="6.14.6"><h3 data-number="6.14.6" class="anchored" data-anchor-id="la-decisione-statistica">
<span class="header-section-number">6.14.6</span> La decisione statistica</h3>
<p>Il processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:</p>
<blockquote class="blockquote">
<p>Controllare (<em>checking</em>) o saggiare (<em>testing</em>) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p.&nbsp;441)</p>
</blockquote>
<p>Ovviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.</p>
<p>In pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test <span class="math inline">\(\mathcal{G}_n\)</span> cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-<span class="math inline">\(p\)</span> con <span class="math inline">\(\alpha\)</span> – i due metodi sono equivalenti.</p>
<p>Il <em>valore-p</em> rappresenta la probabilità di osservare un valore della statistica test <span class="math inline">\(\mathcal{G}_n\)</span> pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-<span class="math inline">\(p\)</span> è <em>minore</em> del livello di significatività <span class="math inline">\(\alpha\)</span>, allora la statistica test cade nella regione di rifiuto di <span class="math inline">\(H_0\)</span> e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.</p>
<p><img src="../../figures/decisione_statistica.png" class="img-fluid" style="width:80.0%"></p>
<p>Per l’esempio in discussione, la statistica <span class="math inline">\(T\)</span> calcolata sopra si distribuisce come <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(\nu = 31\)</span> gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una <span class="math inline">\(t_{31}\)</span> nell’intervallo <span class="math inline">\([1.896, +\infty]\)</span> (test unidirezionale destro), ovvero</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Calculate the upper tail probability for the t-distribution</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="cn">T</span>, df <span class="op">=</span> <span class="fl">31</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0336</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Dato che il valore-p è minore di <span class="math inline">\(\alpha = 0.05\)</span>, <span class="citation" data-cites="mehr_melodies">Mehr et al. (<a href="#ref-mehr_melodies" role="doc-biblioref">2016</a>)</span> rifiutano <span class="math inline">\(H_0\)</span> (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.</p>
</section></section><section id="potenza-del-test" class="level2" data-number="6.15"><h2 data-number="6.15" class="anchored" data-anchor-id="potenza-del-test">
<span class="header-section-number">6.15</span> Potenza del test</h2>
<p>Ritorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere <span class="math inline">\(H_0\)</span> quando essa è vera e dovrebbe respingere <span class="math inline">\(H_0\)</span> in favore dell’alternativa quando <span class="math inline">\(H_1\)</span> è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.</p>
<p><img src="../../figures/potere_statistico.png" class="img-fluid" style="width:51.0%"></p>
<p>Possiamo pensare a <span class="math inline">\(H_0\)</span> come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad <span class="math inline">\(H_1\)</span> come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la <em>potenza del test</em>, ovvero la probabilità <span class="math inline">\(1 - \beta\)</span> di rigettare <span class="math inline">\(H_0\)</span> quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il <em>livello di significatività</em> corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.</p>
<p>Il calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di <span class="math inline">\(\mathcal{G}_n\)</span> quando è vera l’ipotesi alternativa <span class="math inline">\(H_1\)</span>. Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a <span class="math inline">\(H_0\)</span> e ad <span class="math inline">\(H_1\)</span>. In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.</p>
<section id="neyman-e-fisher" class="level3" data-number="6.15.1"><h3 data-number="6.15.1" class="anchored" data-anchor-id="neyman-e-fisher">
<span class="header-section-number">6.15.1</span> Neyman e Fisher</h3>
<p>La procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.</p>
<p>In sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-<span class="math inline">\(p\)</span> rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-<span class="math inline">\(p\)</span> è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.</p>
<p>Al contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-<span class="math inline">\(p\)</span> non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.</p>
<p>Attualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-<span class="math inline">\(p\)</span> in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello <span class="math inline">\(\alpha\)</span> stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo <span class="quarto-unresolved-ref">?sec-errors-s-m</span> esploreremo queste ragioni in dettaglio.</p>
</section></section><section id="la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni" class="level2" data-number="6.16"><h2 data-number="6.16" class="anchored" data-anchor-id="la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni">
<span class="header-section-number">6.16</span> La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni</h2>
<p>Concludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da <span class="citation" data-cites="etz2018become">Etz et al. (<a href="#ref-etz2018become" role="doc-biblioref">2018</a>)</span>. L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.</p>
<p>Questo risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-<span class="math inline">\(p\)</span> calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.</p>
<p>Tuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate <span class="citation" data-cites="etz2018become">(<a href="#ref-etz2018become" role="doc-biblioref">Etz et al., 2018</a>)</span>. Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.</p>
<p>Supponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-<span class="math inline">\(p\)</span> è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr.&nbsp;Bristol stesse semplicemente indovinando.</p>
<p>Supponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-<span class="math inline">\(p\)</span> diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.</p>
<p>Quello che emerge è che, <em>nonostante i dati osservati nei due scenari siano identici</em>, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-<span class="math inline">\(p\)</span>, e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.</p>
<p>Per illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.</p>
<section id="distribuzione-binomiale" class="level3" data-number="6.16.1"><h3 data-number="6.16.1" class="anchored" data-anchor-id="distribuzione-binomiale">
<span class="header-section-number">6.16.1</span> Distribuzione Binomiale</h3>
<p>La distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente <span class="math inline">\(k\)</span> successi in <span class="math inline">\(n\)</span> tentativi è la seguente:</p>
<p><span class="math display">\[
P(X = k) = \binom{n}{k} \times p^k \times (1-p)^{(n-k)}
\]</span></p>
<p>Qui, <span class="math inline">\(\binom{n}{k}\)</span> rappresenta il coefficiente binomiale, <span class="math inline">\(p\)</span> è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e <span class="math inline">\((1-p)\)</span> è la probabilità di un singolo fallimento.</p>
<p>Per calcolare il valore-<span class="math inline">\(p\)</span> in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">n_binomial</span> <span class="op">&lt;-</span> <span class="fl">6</span>  <span class="co"># Number of fixed trials for the binomial distribution</span></span>
<span><span class="va">n_success</span> <span class="op">&lt;-</span> <span class="fl">5</span>  <span class="co"># Desired number of successes</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Probability of success</span></span>
<span></span>
<span><span class="co"># Calculate the p-value for the binomial distribution</span></span>
<span><span class="va">p_value_binomial</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="va">n_success</span> <span class="op">-</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="va">n_binomial</span>, prob <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p_value_binomial</span></span>
<span><span class="co">#&gt; [1] 0.109</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="distribuzione-geometrica-negativa" class="level3" data-number="6.16.2"><h3 data-number="6.16.2" class="anchored" data-anchor-id="distribuzione-geometrica-negativa">
<span class="header-section-number">6.16.2</span> Distribuzione Geometrica Negativa</h3>
<p>Nel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.</p>
<p>La distribuzione geometrica negativa modella il numero di fallimenti <span class="math inline">\(k\)</span> che si verificano prima di ottenere un numero prefissato <span class="math inline">\(r\)</span> di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo <span class="math inline">\(p\)</span>.</p>
<p>La probabilità di osservare esattamente <span class="math inline">\(k\)</span> fallimenti prima di ottenere <span class="math inline">\(r\)</span> successi è data da:</p>
<p><span class="math display">\[
P(X = k) = \binom{k+r-1}{k} p^r (1-p)^k,
\]</span></p>
<p>dove:</p>
<ul>
<li>
<span class="math inline">\(k\)</span> è il numero di fallimenti,</li>
<li>
<span class="math inline">\(r\)</span> è il numero di successi desiderato,</li>
<li>
<span class="math inline">\(p\)</span> è la probabilità di successo in ogni prova,</li>
<li>
<span class="math inline">\(\binom{k+r-1}{k}\)</span> è il coefficiente binomiale che rappresenta il numero di modi possibili in cui <span class="math inline">\(k\)</span> fallimenti e <span class="math inline">\(r\)</span> successi possono essere ordinati.</li>
</ul>
<p>Nel nostro caso specifico:</p>
<ul>
<li>
<span class="math inline">\(r = 5\)</span> (successi desiderati),</li>
<li>
<span class="math inline">\(p = 0.5\)</span> (probabilità di indovinare correttamente sotto l’ipotesi nulla),</li>
<li>
<span class="math inline">\(k\)</span> varia da 0 a 1 (possibili fallimenti prima del quinto successo).</li>
</ul>
<p>Il valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:</p>
<p><span class="math display">\[
\text{valore-p} = \sum_{k=0}^{1} \binom{k+5-1}{k} (0.5)^5 (0.5)^k.
\]</span></p>
<p>Implementazione:</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">n_binomial</span> <span class="op">&lt;-</span> <span class="fl">6</span>  <span class="co"># Number of fixed trials for the binomial distribution</span></span>
<span><span class="va">n_success</span> <span class="op">&lt;-</span> <span class="fl">5</span>  <span class="co"># Desired number of successes</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Probability of success (guessing the tea cup)</span></span>
<span></span>
<span><span class="co"># Calculate the p-value for the negative binomial distribution</span></span>
<span><span class="va">p_value_geom_corrected</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">k</span> <span class="kw">in</span> <span class="fl">0</span><span class="op">:</span><span class="op">(</span><span class="va">n_binomial</span> <span class="op">-</span> <span class="va">n_success</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>  <span class="co"># Number of failures before the 5th success</span></span>
<span>  <span class="va">p_value_geom_corrected</span> <span class="op">&lt;-</span> <span class="va">p_value_geom_corrected</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">k</span> <span class="op">+</span> <span class="va">n_success</span> <span class="op">-</span> <span class="fl">1</span>, <span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span><span class="op">^</span><span class="va">k</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">p</span><span class="op">^</span><span class="va">n_success</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">p_value_geom_corrected</span></span>
<span><span class="co">#&gt; [1] 0.0312</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In conclusione,</p>
<ul>
<li><p>per la distribuzione binomiale, il p-value è <span class="math inline">\(0.109\)</span>, che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr.&nbsp;Bristol stia indovinando.</p></li>
<li><p>per la distribuzione geometrica negativa, il p-value è <span class="math inline">\(0.031\)</span>, che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr.&nbsp;Bristol non sta semplicemente indovinando.</p></li>
</ul>
<p>La presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda <span class="citation" data-cites="wasserstein2016asa">Wasserstein &amp; Lazar (<a href="#ref-wasserstein2016asa" role="doc-biblioref">2016</a>)</span>; <span class="citation" data-cites="benjamin2018redefine">Benjamin et al. (<a href="#ref-benjamin2018redefine" role="doc-biblioref">2018</a>)</span>) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.</p>
</section><section id="approccio-bayesiano" class="level3" data-number="6.16.3"><h3 data-number="6.16.3" class="anchored" data-anchor-id="approccio-bayesiano">
<span class="header-section-number">6.16.3</span> Approccio Bayesiano</h3>
<p>Nel loro lavoro, <span class="citation" data-cites="etz2018become">Etz et al. (<a href="#ref-etz2018become" role="doc-biblioref">2018</a>)</span> propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:</p>
<ol type="1">
<li><p><strong>Stabilire Probabilità a Priori</strong>: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr.&nbsp;Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr.&nbsp;Bristol stia semplicemente indovinando (con un tasso di successo del 50%).</p></li>
<li><p><strong>Aggiornare le Probabilità con Dati Osservati</strong>: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.</p></li>
<li><p><strong>Calcolare il Fattore di Bayes</strong>: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.</p></li>
</ol>
<p>Nel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.</p>
<p><span class="citation" data-cites="etz2018become">Etz et al. (<a href="#ref-etz2018become" role="doc-biblioref">2018</a>)</span> concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di <span class="citation" data-cites="van2020class">Doorn et al. (<a href="#ref-van2020class" role="doc-biblioref">2020</a>)</span>.</p>
</section></section><section id="malintesi-sul-valore-p" class="level2" data-number="6.17"><h2 data-number="6.17" class="anchored" data-anchor-id="malintesi-sul-valore-p">
<span class="header-section-number">6.17</span> Malintesi sul valore-p</h2>
<p>Sono diffusi molti malintesi sul valore-p.&nbsp;Ne esaminiamo qui quelli più comuni.</p>
<p><strong>Malinteso 1:</strong> Un valore p non significativo significa che l’ipotesi nulla è vera.</p>
<p>Il malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.</p>
<p>Risultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.</p>
<p>Invece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.</p>
<p>L’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.</p>
<p>L’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.</p>
<p><strong>Malintesto 2:</strong> Un valore p significativo significa che l’ipotesi nulla è falsa.</p>
<p>Come spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.</p>
<p><strong>Malinteso 3:</strong> Un valore p significativo significa che è stato scoperto un effetto importante.</p>
<p>La distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.</p>
<p>Un effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.</p>
<p>Inoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.</p>
<p>Un p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di <span class="math inline">\(H_0\)</span>, non è necessariamente un effetto “importante”.</p>
<p><strong>Malinteso 4:</strong> Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.</p>
<p>Il malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.</p>
<p>Tuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.</p>
<p>In breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.</p>
<p><strong>Malinteso 5:</strong> Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.</p>
<p>Il concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.</p>
<p>In sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.</p>
</section><section id="riflessioni-conclusive" class="level2" data-number="6.18"><h2 data-number="6.18" class="anchored" data-anchor-id="riflessioni-conclusive">
<span class="header-section-number">6.18</span> Riflessioni Conclusive</h2>
<p>Il presente capitolo ha messo in evidenza le numerose limitazioni e i potenziali pericoli dell’approccio frequentista al test dell’ipotesi nulla, portando alla luce una serie di paradossi e malintesi che minano la sua validità come strumento primario per l’inferenza scientifica. In particolare, abbiamo visto come il valore-p, spesso utilizzato come metro di giudizio assoluto per decidere se un risultato è significativo o meno, possa condurre a conclusioni fuorvianti, dipendendo non solo dai dati osservati ma anche dal contesto sperimentale e dalle scelte soggettive del ricercatore. Questo approccio, che si basa su una logica binaria di “accettare” o “rifiutare” l’ipotesi nulla, sembra incapace di cogliere la complessità delle relazioni causali e degli effetti reali presenti nei fenomeni psicologici e sociali. Più profondamente, emerge con chiarezza che il metodo frequentista, lungi dall’essere un sistema oggettivo per la decisione statistica, è invece intriso di convenzioni arbitrarie (come il livello di significatività α = 0.05) e di una visione riduzionistica della probabilità, concepita come frequenza relativa di eventi ripetibili nel tempo piuttosto che come misura della nostra incertezza riguardo a un evento specifico.</p>
<p>Tuttavia, al di là delle critiche tecniche, il problema più grave risiede nella tendenza a considerare il test dell’ipotesi nulla come uno strumento definitivo per valutare la veridicità di ipotesi scientifiche, anziché come un semplice punto di partenza per ulteriori indagini. La cultura prevalente nella comunità scientifica, che premia i risultati “statisticamente significativi”, ha contribuito a creare un ambiente in cui gli studi replicabili sono rari e dove molti risultati pubblicati sono fragili e difficilmente generalizzabili. È qui che l’approccio bayesiano entra in gioco, offrendo una soluzione coerente e robusta che supera molte delle carenze del frequentismo. Al contrario del metodo frequentista, che si concentra su ipotesi nulle arbitrariamente definite e sulle distribuzioni campionarie di statistiche teoriche, il bayesianesimo ci permette di incorporare informazioni pregresse (prior) e di aggiornare queste conoscenze in base ai dati osservati, fornendo una stima diretta della probabilità delle ipotesi di interesse. Questo approccio, che mette al centro la nozione di evidenza, permette di quantificare la forza delle prove a favore di diverse ipotesi, evitando così le dicotomie rigide tra “significativo” e “non significativo” e promuovendo una visione più sfumata e matematicamente fondata dell’inferenza statistica.</p>
<p>In conclusione, il test dell’ipotesi nulla frequentista, pur essendo ampiamente utilizzato, rappresenta uno degli aspetti più controversi e problematici dell’approccio tradizionale. La sua rigidità metodologica e la dipendenza da concetti come il valore <em>p</em> e la significatività statistica lo rendono non solo impreciso, ma anche inadeguato a cogliere la complessità dei fenomeni che la ricerca psicologica si propone di esplorare. Abbandonare questo paradigma non è solo una questione di precisione tecnica, ma di superare una mentalità riduzionista che limita la nostra capacità di interpretare i dati in modo sfumato e contestuale.</p>
<p>L’adozione di metodologie bayesiane, al contrario, offre un quadro più dinamico e flessibile, in cui le ipotesi non sono semplicemente accettate o rifiutate, ma valutate in termini probabilistici. Questo approccio incoraggia un confronto diretto tra modelli e ipotesi contrapposte, permettendo di aggiornare le nostre credenze alla luce dei nuovi dati. Non si tratta solo di un miglioramento tecnico nelle inferenze scientifiche, ma di un invito a ripensare il modo in cui concepiamo la conoscenza e il processo di scoperta. La prospettiva bayesiana, infatti, enfatizza l’incertezza come parte intrinseca della ricerca, trasformandola in uno strumento per affinare le nostre comprensioni piuttosto che un ostacolo da superare.</p>
<p>In un contesto psicologico intrinsecamente complesso e caratterizzato da incertezza, l’approccio bayesiano rappresenta un’opportunità per adottare un’epistemologia più flessibile e razionale. La sua forza risiede nella capacità di adattarsi alla natura multifattoriale dei fenomeni psicologici, integrando in modo coerente e trasparente sia le conoscenze pregresse sia le nuove evidenze. In questo senso, l’adozione del paradigma bayesiano non è soltanto un avanzamento metodologico, ma anche un passo verso una scienza più consapevole, critica e adatta alle sfide della psicologia contemporanea.</p>
</section><section id="esercizi" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="esercizi">Esercizi</h2>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi 1">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>L’Idea di Base del Test di Ipotesi</li>
</ol>
<p>Spiega il principio generale del <em>test di ipotesi nulla</em> in ambito frequentista. In che modo la logica dell’“assumere come vera l’ipotesi nulla fino a prova contraria” è paragonabile al concetto di “presunzione di innocenza” in un processo penale? Quali vantaggi e svantaggi comporta questa impostazione?</p>
<ol start="2" type="1">
<li>Ipotesi di Ricerca vs.&nbsp;Ipotesi Statistica</li>
</ol>
<p>Spiega in che modo l’ipotesi di ricerca (ad esempio, “esiste un effetto della musica sul comportamento dei bambini”) differisce dall’ipotesi statistica che si testa formalmente (ad esempio, “la media di un indice di preferenza è maggiore di 0.5”). Perché spesso la ricerca psicologica non può testare <em>direttamente</em> l’ipotesi di ricerca?</p>
<ol start="3" type="1">
<li>Significatività Statistica e Rilevanza Pratica</li>
</ol>
<p>Che differenza c’è tra “risultato statisticamente significativo” e “risultato rilevante (o importante) dal punto di vista pratico o teorico”? Porta un esempio in cui un test frequenzista possa dare un valore-<span class="math inline">\(p\)</span> molto basso senza che l’effetto sia considerato rilevante nel contesto.</p>
<ol start="4" type="1">
<li>Malinteso: Un Risultato non Significativo Implica Che <span class="math inline">\(H_0\)</span> Sia Vera?</li>
</ol>
<p>Perché è errato concludere che l’ipotesi nulla sia vera quando il test non risulta significativo (cioè quando <span class="math inline">\(p \ge 0.05\)</span>)? Quali altre spiegazioni potrebbero esserci se un esperimento produce un valore-<span class="math inline">\(p\)</span> alto?</p>
<ol start="5" type="1">
<li>Il Ruolo della Variabilità Campionaria</li>
</ol>
<p>In che modo la <strong>variabilità campionaria</strong> (cioè il fatto che stime come la media campionaria varino da campione a campione) influisce sulla necessità di un test di ipotesi? Perché non è sufficiente confrontare la media osservata con il valore ipotizzato per concludere se <span class="math inline">\(H_0\)</span> è falsa?</p>
<ol start="6" type="1">
<li>Errori di I e II Tipo e Potenza del Test</li>
</ol>
<p>Descrivi i concetti di errore di I tipo (falso positivo) e errore di II tipo (falso negativo). Perché i test sono progettati primariamente per controllare l’errore di I tipo? Che cos’è la potenza (<span class="math inline">\(1-\beta\)</span>) di un test?</p>
<ol start="7" type="1">
<li>Il Valore-<span class="math inline">\(p\)</span>: Che Cosa (non) Indica?</li>
</ol>
<p>Spiega la definizione di valore-<span class="math inline">\(p\)</span> secondo l’approccio frequentista. Quali sono due malintesi comuni su ciò che il valore-<span class="math inline">\(p\)</span> <em>non</em> rappresenta?</p>
<ol start="8" type="1">
<li>Critica: Dipendenza dai “Risultati più Estremi Non Osservati”</li>
</ol>
<p>Nell’esempio dell’episodio “The Lady Tasting Tea”, come mai il test di ipotesi frequentista può portare a conclusioni diverse pur avendo gli stessi dati osservati, a seconda di come è definito il “processo di campionamento”? Perché questa è una limitazione?</p>
<ol start="9" type="1">
<li>Controllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo</li>
</ol>
<p>Perché nel test di ipotesi frequentista esiste un’asimmetria per cui si controlla rigorosamente l’errore di I tipo (fissando <span class="math inline">\(\alpha\)</span>), ma non esiste un analogo vincolo obbligatorio sull’errore di II tipo (<span class="math inline">\(\beta\)</span>)? Quali conseguenze pratiche ne derivano per la pianificazione di uno studio?</p>
<ol start="10" type="1">
<li>Limiti dell’Approccio Frequentista e Alternative</li>
</ol>
<p>Riassumi in che senso il test di ipotesi nulla frequentista è ritenuto da alcuni ricercatori insufficiente o fuorviante (es. “dichotomania” del significato, p-value dipendente dal disegno, ecc.). Quali alternative o integrazioni sono state proposte in letteratura per superare questi limiti?</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Soluzioni 1">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Soluzioni 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>L’Idea di Base del Test di Ipotesi</li>
</ol>
<ul>
<li>L’ipotesi nulla (<span class="math inline">\(H_0\)</span>) è considerata “innocente” fino a che l’evidenza non la “condanna”.<br>
</li>
<li>Il test statistico stabilisce la probabilità di osservare dati così (o più) estremi assumendo che <span class="math inline">\(H_0\)</span> sia vera.<br>
</li>
<li>Vantaggio: stabilire un controllo sul rischio di un <strong>falso positivo</strong> (errore di I tipo).<br>
</li>
<li>Svantaggio: non si dimostra direttamente l’ipotesi di ricerca (<span class="math inline">\(H_1\)</span>), ma si prova a “falsificare” <span class="math inline">\(H_0\)</span>.</li>
</ul>
<ol start="2" type="1">
<li>Ipotesi di Ricerca vs.&nbsp;Ipotesi Statistica</li>
</ol>
<ul>
<li>L’ipotesi statistica è una versione <strong>quantificabile</strong> (e falsificabile) dell’ipotesi di ricerca.<br>
</li>
<li>Le ipotesi di ricerca in psicologia sono spesso complesse (costrutti non sempre direttamente misurabili).<br>
</li>
<li>I ricercatori formulano un modello statistico semplificato per rendere l’ipotesi testabile.</li>
</ul>
<ol start="3" type="1">
<li>Significatività Statistica e Rilevanza Pratica</li>
</ol>
<ul>
<li>“Significativo” in senso frequentista significa “dati improbabili se <span class="math inline">\(H_0\)</span> è vera”.<br>
</li>
<li>Non implica necessariamente un effetto ampio o di importanza pratica.<br>
</li>
<li>Con campioni molto grandi, si possono rilevare anche differenze piccolissime, magari prive di valore applicativo.</li>
</ul>
<ol start="4" type="1">
<li>Malinteso: Un Risultato non Significativo Implica Che <span class="math inline">\(H_0\)</span> Sia Vera?</li>
</ol>
<ul>
<li>Un valore-<span class="math inline">\(p\)</span> “alto” segnala che i dati non forniscono sufficiente evidenza per rifiutare <span class="math inline">\(H_0\)</span>, <strong>non</strong> che <span class="math inline">\(H_0\)</span> è vera.<br>
</li>
<li>Possibile mancanza di potenza statistica (campione troppo piccolo) o presenza di effetti molto ridotti.<br>
</li>
<li>L’approccio frequentista non quantifica la probabilità che <span class="math inline">\(H_0\)</span> sia vera, ma la probabilità di osservare certi dati <em>assumendo</em> che <span class="math inline">\(H_0\)</span> lo sia.</li>
</ul>
<ol start="5" type="1">
<li>Il Ruolo della Variabilità Campionaria</li>
</ol>
<ul>
<li>Anche se la media campionaria si discosta da <span class="math inline">\(H_0\)</span>, potremmo aver ottenuto quella differenza per puro caso.<br>
</li>
<li>Occorre stabilire <em>quanto</em> discostamento sia “raro” secondo la distribuzione campionaria ipotizzata da <span class="math inline">\(H_0\)</span>.<br>
</li>
<li>Il test calcola quante volte, nel lungo periodo, si osservano dati così estremi casualmente.</li>
</ul>
<ol start="6" type="1">
<li>Errori di I e II Tipo e Potenza del Test</li>
</ol>
<ul>
<li>Errore di I tipo: rigettare <span class="math inline">\(H_0\)</span> quando è vera.<br>
</li>
<li>Errore di II tipo: non rigettare <span class="math inline">\(H_0\)</span> quando è falsa.<br>
</li>
<li>Il test frequenzista fissa una soglia <span class="math inline">\(\alpha\)</span> (livello di significatività) per controllare l’errore di I tipo.<br>
</li>
<li>La potenza quantifica la probabilità di individuare realmente un effetto quando esso esiste.</li>
</ul>
<ol start="7" type="1">
<li>Il Valore-<span class="math inline">\(p\)</span>: Che Cosa (non) Indica?</li>
</ol>
<ul>
<li>Il valore-<span class="math inline">\(p\)</span> è la probabilità di ottenere un risultato almeno così estremo <em>se <span class="math inline">\(H_0\)</span> è vera</em>.<br>
</li>
<li>Malinteso 1: pensare che indichi la probabilità che <span class="math inline">\(H_0\)</span> sia vera o falsa.<br>
</li>
<li>Malinteso 2: confondere “<span class="math inline">\(p &lt; 0.05\)</span> =&gt; probabilità 95% che l’effetto sia vero” (non è così!).</li>
</ul>
<ol start="8" type="1">
<li>Critica: Dipendenza dai “Risultati più Estremi Non Osservati”</li>
</ol>
<ul>
<li>Il valore-<span class="math inline">\(p\)</span> frequenzista include la probabilità di osservare anche “risultati più estremi” non avvenuti nell’esperimento.<br>
</li>
<li>Se l’esperimento era “fissare a priori 6 tazze” vs.&nbsp;“continuare finché non ottiene 5 successi”, può cambiare la distribuzione usata (binomiale vs.&nbsp;geometrica negativa).<br>
</li>
<li>Questo mostra che il valore-<span class="math inline">\(p\)</span> dipende dal contesto sperimentale, non solo dai dati effettivi.</li>
</ul>
<ol start="9" type="1">
<li>Controllo dell’Errore di I Tipo, ma Non dell’Errore di II Tipo</li>
</ol>
<ul>
<li>Si vuole evitare di “condannare” un’ipotesi nulla “innocente”.<br>
</li>
<li>L’errore di II tipo spesso viene trascurato e può essere molto alto se il campione è piccolo.<br>
</li>
<li>Conseguenze: molti studi hanno potenza insufficiente; i “falsi negativi” rimangono frequenti.</li>
</ul>
<ol start="10" type="1">
<li>Limiti dell’Approccio Frequentista e Alternative</li>
</ol>
<ul>
<li>Critiche: inflazione di falsi positivi, dipendenza arbitraria da <span class="math inline">\(\alpha=0.05\)</span>, scarsa attenzione alla dimensione dell’effetto, interpretazioni errate del p-value.<br>
</li>
<li>Alternative:
<ul>
<li>
<strong>Approccio bayesiano</strong> (fattori di Bayes, posteriori, credibilità).<br>
</li>
<li>
<strong>Confidence intervals</strong> ampliati da riflessioni su potenza e dimensione dell’effetto.<br>
</li>
<li>
<strong>Misure dell’effetto</strong> e analisi approfondite invece di un giudizio binario su “p&lt;0.05”.</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi 2">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Esercizi “A Mano”</p>
<p>Questi esercizi si possono affrontare con le formule del test di ipotesi (z-test o t-test per la media, test di proporzioni, ecc.), senza ricorrere a software.</p>
<p><strong>Esercizio 1: One-sample t-test sulla SWLS</strong></p>
<ol type="1">
<li>
<p>Hai un piccolo campione di <span class="math inline">\(n=9\)</span> studenti, con punteggi SWLS (ipotetici) riportati di seguito:</p>
<p><span class="math display">\[
21, \ 18, \ 26, \ 20, \ 23, \ 16, \ 22, \ 19, \ 25
\]</span></p>
</li>
<li><p>Supponi che, in letteratura, la <strong>media teorica</strong> su popolazioni simili sia di circa <span class="math inline">\(\mu_0 = 20\)</span>.</p></li>
<li><p><strong>Ipotesi nulla</strong> <span class="math inline">\((H_0)\)</span>: la media del campione non differisce da 20 (cioè <span class="math inline">\(\mu = 20\)</span>).<br><strong>Ipotesi alternativa</strong> <span class="math inline">\((H_1)\)</span>: la media del campione differisce da 20 (two-sided test).</p></li>
<li>
<p><strong>Richiesta</strong>:</p>
<ul>
<li>Calcola la media campionaria <span class="math inline">\(\bar{X}\)</span> e la deviazione standard campionaria <span class="math inline">\(s\)</span>.<br>
</li>
<li>Esegui un <strong>t-test</strong> a mano (con formula <span class="math inline">\(t = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}\)</span>).<br>
</li>
<li>Stabilisci se, con <span class="math inline">\(\alpha=0.05\)</span> (test a due code), si rifiuta o meno <span class="math inline">\(H_0\)</span>.</li>
</ul>
</li>
<li><p><strong>Suggerimento</strong>: Usa la tabella della distribuzione t (o ricorri a tavole semplificate) per trovare il valore critico a <span class="math inline">\(df = n-1 = 8\)</span>. Solo per questo step, usa R.</p></li>
</ol>
<p><strong>Esercizio 22: One-sample t-test sulla LSNS-6</strong></p>
<ol type="1">
<li>
<p>Hai un campione di <span class="math inline">\(n=8\)</span> persone anziane, con punteggi LSNS-6 (Scala della Rete Sociale di Lubben) ipotetici (in realtà userai i dati raccolti):</p>
<p><span class="math display">\[
10,\ 14,\ 8,\ 13,\ 12,\ 7,\ 15,\ 9
\]</span></p>
</li>
<li><p>In letteratura si suppone che un punteggio <strong>medio</strong> su popolazioni simili sia <span class="math inline">\(\mu_0 = 12\)</span>.</p></li>
<li><p><strong>Ipotesi nulla</strong>: <span class="math inline">\(\mu = 12\)</span>.<br><strong>Ipotesi alternativa</strong>: <span class="math inline">\(\mu \neq 12\)</span>.</p></li>
<li>
<p><strong>Richiesta</strong>:</p>
<ul>
<li>Calcola media e deviazione standard.<br>
</li>
<li>Calcola la statistica <span class="math inline">\(t\)</span> e confrontala con il valore critico per <span class="math inline">\(\alpha=0.05\)</span>, two-sided, con <span class="math inline">\(df = 7\)</span>.<br>
</li>
<li>Concludi se rifiuti l’ipotesi nulla o meno.</li>
</ul>
</li>
</ol>
<p><strong>Esercizio 3: Due campioni indipendenti (SWLS)</strong></p>
<ol type="1">
<li>
<p>Considera i dati raccolti dal tuo gruppo e quelli di un altro gruppo TPV (es., Gruppo A = 6 persone, Gruppo B = 5 persone) che hanno compilato la SWLS. Riporta per ipotesi i seguenti punteggi medi e DS (usa i dati reali):</p>
<ul>
<li>Gruppo A: <span class="math inline">\(\bar{X}_A = 24,\ s_A=4,\ n_A=6\)</span><br>
</li>
<li>Gruppo B: <span class="math inline">\(\bar{X}_B = 19,\ s_B=3,\ n_B=5\)</span>
</li>
</ul>
</li>
<li><p>Vuoi testare se le due medie differiscono in modo significativo (<span class="math inline">\(\alpha=0.05\)</span>, due code).</p></li>
<li><p><strong>Ipotesi nulla</strong>: <span class="math inline">\(\mu_A = \mu_B\)</span>.<br><strong>Ipotesi alternativa</strong>: <span class="math inline">\(\mu_A \neq \mu_B\)</span>.</p></li>
<li>
<p><strong>Richiesta</strong>:</p>
<ul>
<li>Calcola la statistica <span class="math inline">\(t\)</span> di un <strong>two-sample t-test</strong> (varianze incognite, <em>assunte uguali</em>).<br>
</li>
<li>Usa la formula con la “varianza pooled”.<br>
</li>
<li>Calcola i <span class="math inline">\(df\)</span> approssimati come <span class="math inline">\(n_A + n_B - 2\)</span>.<br>
</li>
<li>Concludi se rifiuti <span class="math inline">\(H_0\)</span>.</li>
</ul>
</li>
</ol>
<p><strong>Esercizio 4: Test su una proporzione (SWLS recodificata)</strong></p>
<ol type="1">
<li><p>A volte si trasforma la SWLS in una variabile binaria es. “<span class="math inline">\(\mathrm{SWLS} \ge 24\)</span> = soddisfatto, <span class="math inline">\(\mathrm{SWLS}&lt;24\)</span> = non soddisfatto”.<br></p></li>
<li><p>Considera i dati raccolti e i corrispondenti risultati binari (Sì/No) siano 4 “soddisfatti” e 6 “non soddisfatti”.</p></li>
<li><p><strong>Ipotesi nulla</strong>: la proporzione di “soddisfatti” è <span class="math inline">\(p_0 = 0.50\)</span> (ipotizzi che metà dei partecipanti sia soddisfatta).<br><strong>Ipotesi alternativa</strong>: la proporzione <span class="math inline">\(\neq 0.50\)</span>.</p></li>
<li><p>Calcola la statistica <span class="math inline">\(Z\)</span> per una proporzione (usando la formula della normal approx. se <span class="math inline">\(\hat{p}=4/10\)</span>).<br></p></li>
<li><p>Confronta <span class="math inline">\(|Z|\)</span> con il valore critico a <span class="math inline">\(\alpha=0.05\)</span> (due code), <span class="math inline">\(z_{0.025}\approx 1.96\)</span>. Concludi.</p></li>
</ol>
<p><strong>Esercizio 5: Confronto fra due proporzioni (LSNS-6 recodificata)</strong></p>
<ol type="1">
<li>Considerai dati di due gruppi TPV (Gruppo A, Gruppo B).<br>
</li>
<li>Supponi che, per Gruppo A (<span class="math inline">\(n_A=8\)</span>), 3 persone abbiano un punteggio <span class="math inline">\(\ge 12\)</span> (considerato “buon supporto”). Per Gruppo B (<span class="math inline">\(n_B=10\)</span>), 7 persone siano <span class="math inline">\(\ge 12\)</span> – usa i dati reali.</li>
<li>
<strong>Ipotesi nulla</strong>: <span class="math inline">\(\,p_A = p_B\)</span>.<br><strong>Ipotesi alternativa</strong>: <span class="math inline">\(\,p_A \neq p_B\)</span>.<br>
</li>
<li>Calcola <span class="math inline">\(\hat{p}_A = 3/8\)</span> e <span class="math inline">\(\hat{p}_B = 7/10\)</span>.<br>
</li>
<li>Fai il test per il confronto di due proporzioni (con la formula per la “pooled proportion”). Decidi se c’è differenza significativa al 5%.</li>
</ol>
<p>Esercizi “Con R”</p>
<p>Ora proponiamo 5 esercizi da svolgere con il software <strong>R</strong>. Naturalmente, dovrete caricare il vostro dataset reale (ad esempio in formato CSV o XLS) e adattare i comandi di R.</p>
<p><strong>Esercizio 1: Calcolo e t-test di una sola media per la SWLS</strong></p>
<ol type="1">
<li>
<p><strong>Caricate</strong> in R i vostri dati SWLS in un vettore, es.:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">swls_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>  <span class="co"># I vostri punteggi</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li>
<p>Stampate la <strong>media</strong> e la <strong>deviazione standard</strong>:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">swls_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">swls_data</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p><strong>Test</strong> se la media differisce da 24, usando <code>t.test(swls_data, mu = 24)</code>.<br></p></li>
<li><p>Osservate il p-value e concludete se rifiutate <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu=24\)</span> vs <span class="math inline">\(H_1\)</span>: <span class="math inline">\(\mu \neq 24\)</span>.</p></li>
</ol>
<p><strong>Esercizio 2: Calcolo e t-test di una sola media per la LSNS-6</strong></p>
<ol type="1">
<li>
<p>Fate lo stesso per la LSNS:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">lsns_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>  <span class="co"># I vostri punteggi</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p>Calcolate <code>mean(lsns_data)</code>, <code>sd(lsns_data)</code>.<br></p></li>
<li><p>Eseguite un test con <code>t.test(lsns_data, mu = X)</code> dove <span class="math inline">\(X\)</span> è un valore teorico (ad es. 12 o 10, a seconda delle informazioni di letteratura).<br></p></li>
<li><p>Interpretate l’output, guardando <code>estimate</code>, <code>conf.int</code>, <code>p-value</code>.</p></li>
</ol>
<p><strong>Esercizio 3: Confronto di due medie (SWLS) con due gruppi</strong></p>
<ol type="1">
<li>
<p>Considerate i dati di due gruppi TPV. Avete due vettori in R:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">groupA</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>  <span class="co"># SWLS di chi appartiene al gruppo A</span></span>
<span><span class="va">groupB</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>  <span class="co"># SWLS di chi appartiene al gruppo B</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p>Calcolate <code>mean(groupA)</code>, <code>mean(groupB)</code>.<br></p></li>
<li>
<p>Eseguite:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">groupA</span>, <span class="va">groupB</span>, var.equal <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>  <span class="co"># Welch Two Sample t-test</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p>Confrontate la <strong>differenza</strong> delle medie riportata con l’<strong>intervallo di confidenza</strong>. Il p-value indica se la differenza è significativa (ipotesi nulla: medie uguali).</p></li>
</ol>
<p><strong>Esercizio 4: Test su una proporzione (ricodifica SWLS)</strong></p>
<ol type="1">
<li>
<p>Ricodificate i vostri punteggi SWLS in “1 = soddisfatto” / “0 = non soddisfatto”. Ad esempio:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">satisfied</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">swls_data</span> <span class="op">&gt;=</span> <span class="fl">24</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li>
<p>Contate la proporzione di “1”:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">satisfied</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p>Effettuate il test con <code>prop.test(sum(satisfied), length(satisfied), p = 0.5)</code> (se ipotizzate <span class="math inline">\(p_0=0.5\)</span>).<br></p></li>
<li><p>Guardate l’output e interpretate: l’intervallo di confidenza e il p-value.</p></li>
</ol>
<p><strong>Esercizio 5: Confronto di due proporzioni (ricodifica LSNS)</strong></p>
<ol type="1">
<li>
<p>Fate una ricodifica binaria sul vostro vettore LSNS, ad esempio “1 se <span class="math inline">\(\ge12\)</span>, 0 se &lt;12”:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">good_support</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">lsns_data</span> <span class="op">&gt;=</span> <span class="fl">12</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li>
<p>Separate i partecipanti in due gruppi (ad esempio, un gruppo “A” e un gruppo “B”):</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>groupA_inds <span class="ot">&lt;-</span> (some condition)  <span class="co"># righe che corrispondono a Gruppo A</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>groupB_inds <span class="ot">&lt;-</span> (some other condition)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</li>
<li><p>Calcolate <code>sum(good_support[groupA_inds])</code>, <code>length(groupA_inds)</code> e idem per groupB.<br></p></li>
<li><p>Usate <code>prop.test(x = c(...), n = c(...))</code> per confrontare le due proporzioni.<br></p></li>
<li><p>Concludete: se p-value &lt; 0.05, potete rifiutare <span class="math inline">\(H_0\)</span> (le due proporzioni sono uguali).</p></li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-important no-icon callout-titled" title="Problemi 3">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Problemi 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Esercizio 1 – P-value e Interpretazione Probabilistica</p>
<p>Spiega perché il valore-<span class="math inline">\(p\)</span> del test di ipotesi nulla (frequentista) <strong>non</strong> può essere interpretato come “probabilità che l’ipotesi nulla sia vera” e in che modo l’approccio bayesiano fornisce invece una “probabilità a posteriori” sull’ipotesi. Descrivi <strong>due</strong> possibili conseguenze pratiche di questa differenza di interpretazione.</p>
<p>Esercizio 2 – Ruolo dei “Risultati più Estremi Non Osservati”</p>
<p>Nel test frequentista, il valore-<span class="math inline">\(p\)</span> si basa anche sulla probabilità di risultati <strong>più estremi</strong> di quelli effettivamente osservati, ma che <strong>non</strong> si sono verificati. Perché questo è considerato un <strong>limite</strong> (o un paradosso) e in che modo un’analisi bayesiana eviterebbe (o ridurrebbe) questo problema?</p>
<p>Esercizio 3 – Dipendenza dal Disegno Sperimentale e Optional Stopping</p>
<p>Nel test di ipotesi frequenzista, il valore-<span class="math inline">\(p\)</span> può cambiare se il ricercatore modifica il <strong>piano</strong> di raccolta dati (ad es. fermare la raccolta quando si ottiene un certo risultato). Perché si parla di “problema dell’optional stopping”? Come gestisce invece l’approccio bayesiano la decisione di proseguire o fermare un esperimento sulla base dei dati via via raccolti?</p>
<p>Esercizio 4 – Significatività Statistica vs.&nbsp;Dimensione dell’Effetto</p>
<p>Uno dei limiti dell’approccio frequentista è la confusione tra “significatività statistica” (p&lt;0.05) e “importanza/ampiezza dell’effetto”. Spiega in che modo l’approccio bayesiano può <strong>incorporare</strong> in modo più diretto la dimensione dell’effetto e l’incertezza a riguardo (tramite le “distribuzioni a posteriori” o “intervalli di credibilità”).</p>
<p>Esercizio 5 – Problemi di Replicabilità: Come Confrontare Modelli?</p>
<p>Si osserva spesso che i risultati frequentisti (p&lt;0.05) non si replicano bene in studi successivi. Descrivi come un’analisi bayesiana (con i “fattori di Bayes” o i “posterior odds”) possa dare un <strong>quadro più flessibile</strong> per confrontare ipotesi alternative, riducendo il rischio di eccessive conclusioni basate su un singolo p-value.</p>
</div>
</div>
</div>
<div class="callout callout-style-simple callout-tip no-icon callout-titled" title="Soluzioni 3">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Soluzioni 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Soluzione 1 – P-value e Probabilità dell’Ipotesi</p>
<ul>
<li>
<strong>Punto chiave</strong>: Il <strong>valore-<span class="math inline">\(p\)</span></strong> è la probabilità di ottenere dati “uguali o più estremi” <em>dando per vera</em> l’ipotesi nulla. Invece, <strong>“probabilità che <span class="math inline">\(H_0\)</span> sia vera”</strong> sarebbe un concetto diverso: è la probabilità dell’ipotesi data i dati osservati (interpretazione inversa).<br>
</li>
<li>
<strong>Conseguenze pratiche</strong>:
<ol type="1">
<li>Un p-value “basso” non dice “quanto è probabile che <span class="math inline">\(H_0\)</span> sia falsa”, ma solo che quei dati sarebbero rari sotto <span class="math inline">\(H_0\)</span>.<br>
</li>
<li>I ricercatori spesso sovrastimano la “conferma” contro <span class="math inline">\(H_0\)</span> o interpretano male un p&gt;0.05 come “ipotesi nulla vera”.<br>
</li>
</ol>
</li>
<li>
<strong>Approccio bayesiano</strong>: Consente di calcolare una <strong>posterior probability</strong> di <span class="math inline">\(H_0\)</span> (o di <span class="math inline">\(H_1\)</span>) grazie alla regola di Bayes, purché si disponga di una prior e di un modello.</li>
</ul>
<p>Soluzione 2 – Risultati più Estremi Non Osservati</p>
<ul>
<li>
<strong>Problema</strong>: Nel frequentismo, il valore-<span class="math inline">\(p\)</span> integra la probabilità di dati che <em>non</em> si sono verificati (“what if scenario”). Ciò porta a dipendere da un insieme di risultati ipotetici e a potenziali paradossi (e.g.&nbsp;“Lady Tasting Tea”).<br>
</li>
<li>
<strong>Limite</strong>: Può capitare che stessi dati osservati, ma piani di raccolta diversi, generino p-value diversi.<br>
</li>
<li>
<strong>Bayesian</strong>: Calcola la verosimiglianza <em>solo</em> sui dati effettivi e aggiorna la prior → “focus su ciò che è effettivamente avvenuto”. Non serve considerare a posteriori “risultati più estremi” che non si sono verificati, se non in misura minima (attraverso l’integrazione sulle possibili distribuzioni posteriori, ma con un meccanismo diverso dal p-value).</li>
</ul>
<p>Soluzione 3 – Optional Stopping e Disegno Sperimentale</p>
<ul>
<li>
<strong>Optional Stopping</strong>: In un test frequentista, se continuiamo ad analizzare i dati e fermiamo la raccolta <em>non appena</em> otteniamo p&lt;0.05, si gonfia il rischio di errore di I tipo.<br>
</li>
<li>
<strong>Limite</strong>: Il p-value frequentista dipende dall’idea di un “protocollo fisso” a priori. Se si viola questo piano (aggiungendo dati finché non si ottiene “significatività”), il test non è più valido.<br>
</li>
<li>
<strong>Bayesiano</strong>: L’approccio consente un <strong>monitoraggio sequenziale</strong> (monitoring) dei dati: si aggiorna la distribuzione a posteriori man mano che arrivano nuove osservazioni, e fermarsi quando la posterior probability (o il fattore di Bayes) supera (o non supera) una certa soglia. Questo non invalida formalmente l’inferenza perché si sta accumulando evidenza in modo coerente con Bayes.</li>
</ul>
<p>Soluzione 4 – Ampiezza dell’Effetto e Intervalli di Credibilità</p>
<ul>
<li>
<strong>Frequenza</strong>: Un p-value significativo non dice <em>quanto</em> è grande l’effetto, solo che non si spiega “facilmente” con <span class="math inline">\(H_0=0\)</span>.<br>
</li>
<li>
<strong>Limite</strong>: Spesso si confonde “p&lt;0.05” con “effetto grande/impact significativo”: in realtà, la dimensione potrebbe essere piccola.<br>
</li>
<li>
<strong>Bayesiano</strong>: Offre una <strong>distribuzione a posteriori</strong> sull’effetto (<span class="math inline">\(\theta\)</span>), da cui si può ricavare un <strong>intervallo di credibilità</strong> (dove, ad esempio, c’è il 95% di probabilità che <span class="math inline">\(\theta\)</span> si trovi in quell’intervallo). Consente di valutare se l’effetto è <em>davvero</em> grande o molto stretto attorno allo 0.</li>
</ul>
<p>Soluzione 5 – Replicabilità e Confronto di Ipotesi</p>
<ul>
<li>
<strong>Problema di replicabilità</strong>: Molti studi con p&lt;0.05 non vengono replicati (forse per effetti piccoli, scarsa potenza, pubblicazione selettiva, etc.).<br>
</li>
<li>
<strong>Limite</strong>: Un singolo p-value non dà informazioni su “quanto credere a <span class="math inline">\(H_1\)</span> rispetto a <span class="math inline">\(H_0\)</span>” e non aiuta a cumulare evidenze in analisi meta-analitiche in modo flessibile.<br>
</li>
<li>
<strong>Bayesiano</strong>: Utilizza <strong>fattori di Bayes</strong> (Bayes Factor) o “posterior odds”, confrontando due modelli (es. <span class="math inline">\(H_0\)</span> vs <span class="math inline">\(H_1\)</span>). Se i dati futuri confermano una delle ipotesi, la posterior si rafforza. È un sistema più graduale e cumulativo di aggiornamento della credenza, riducendo la tendenza a “collezionare p&lt;0.05”.</li>
</ul>
</div>
</div>
</div>
</section><section id="informazioni-sullambiente-di-sviluppo" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="informazioni-sullambiente-di-sviluppo">Informazioni sull’Ambiente di Sviluppo</h2>
<div class="cell" data-layout-align="center">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.5.1 (2025-06-13)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20</span></span>
<span><span class="co">#&gt; Running under: macOS Sequoia 15.6.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] C/UTF-8/C/C/C/C</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; time zone: Europe/Rome</span></span>
<span><span class="co">#&gt; tzcode source: internal</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt;  [1] mice_3.18.0           pillar_1.11.0         tinytable_0.13.0     </span></span>
<span><span class="co">#&gt;  [4] patchwork_1.3.2       ggdist_3.3.3          tidybayes_3.0.7      </span></span>
<span><span class="co">#&gt;  [7] bayesplot_1.14.0      ggplot2_3.5.2         reliabilitydiag_0.2.1</span></span>
<span><span class="co">#&gt; [10] priorsense_1.1.1      posterior_1.6.1       loo_2.8.0            </span></span>
<span><span class="co">#&gt; [13] rstan_2.32.7          StanHeaders_2.32.10   brms_2.22.0          </span></span>
<span><span class="co">#&gt; [16] Rcpp_1.1.0            sessioninfo_1.2.3     conflicted_1.2.0     </span></span>
<span><span class="co">#&gt; [19] janitor_2.2.1         matrixStats_1.5.0     modelr_0.1.11        </span></span>
<span><span class="co">#&gt; [22] tibble_3.3.0          dplyr_1.1.4           tidyr_1.3.1          </span></span>
<span><span class="co">#&gt; [25] rio_1.2.3             here_1.0.1           </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] Rdpack_2.6.4          gridExtra_2.3         inline_0.3.21        </span></span>
<span><span class="co">#&gt;  [4] sandwich_3.1-1        rlang_1.1.6           magrittr_2.0.3       </span></span>
<span><span class="co">#&gt;  [7] multcomp_1.4-28       snakecase_0.11.1      compiler_4.5.1       </span></span>
<span><span class="co">#&gt; [10] systemfonts_1.2.3     vctrs_0.6.5           stringr_1.5.1        </span></span>
<span><span class="co">#&gt; [13] pkgconfig_2.0.3       shape_1.4.6.1         arrayhelpers_1.1-0   </span></span>
<span><span class="co">#&gt; [16] fastmap_1.2.0         backports_1.5.0       rmarkdown_2.29       </span></span>
<span><span class="co">#&gt; [19] nloptr_2.2.1          ragg_1.5.0            purrr_1.1.0          </span></span>
<span><span class="co">#&gt; [22] jomo_2.7-6            xfun_0.53             glmnet_4.1-10        </span></span>
<span><span class="co">#&gt; [25] cachem_1.1.0          jsonlite_2.0.0        pan_1.9              </span></span>
<span><span class="co">#&gt; [28] broom_1.0.9           parallel_4.5.1        R6_2.6.1             </span></span>
<span><span class="co">#&gt; [31] stringi_1.8.7         RColorBrewer_1.1-3    rpart_4.1.24         </span></span>
<span><span class="co">#&gt; [34] boot_1.3-32           lubridate_1.9.4       estimability_1.5.1   </span></span>
<span><span class="co">#&gt; [37] iterators_1.0.14      knitr_1.50            zoo_1.8-14           </span></span>
<span><span class="co">#&gt; [40] pacman_0.5.1          nnet_7.3-20           Matrix_1.7-4         </span></span>
<span><span class="co">#&gt; [43] splines_4.5.1         timechange_0.3.0      tidyselect_1.2.1     </span></span>
<span><span class="co">#&gt; [46] abind_1.4-8           codetools_0.2-20      curl_7.0.0           </span></span>
<span><span class="co">#&gt; [49] pkgbuild_1.4.8        lattice_0.22-7        withr_3.0.2          </span></span>
<span><span class="co">#&gt; [52] bridgesampling_1.1-2  coda_0.19-4.1         evaluate_1.0.5       </span></span>
<span><span class="co">#&gt; [55] survival_3.8-3        RcppParallel_5.1.11-1 tensorA_0.36.2.1     </span></span>
<span><span class="co">#&gt; [58] checkmate_2.3.3       foreach_1.5.2         stats4_4.5.1         </span></span>
<span><span class="co">#&gt; [61] reformulas_0.4.1      distributional_0.5.0  generics_0.1.4       </span></span>
<span><span class="co">#&gt; [64] rprojroot_2.1.1       rstantools_2.5.0      scales_1.4.0         </span></span>
<span><span class="co">#&gt; [67] minqa_1.2.8           xtable_1.8-4          glue_1.8.0           </span></span>
<span><span class="co">#&gt; [70] emmeans_1.11.2-8      tools_4.5.1           lme4_1.1-37          </span></span>
<span><span class="co">#&gt; [73] mvtnorm_1.3-3         grid_4.5.1            rbibutils_2.3        </span></span>
<span><span class="co">#&gt; [76] QuickJSR_1.8.0        colorspace_2.1-1      nlme_3.1-168         </span></span>
<span><span class="co">#&gt; [79] cli_3.6.5             textshaping_1.0.3     svUnit_1.0.8         </span></span>
<span><span class="co">#&gt; [82] Brobdingnag_1.2-9     V8_7.0.0              gtable_0.3.6         </span></span>
<span><span class="co">#&gt; [85] digest_0.6.37         TH.data_1.1-4         htmlwidgets_1.6.4    </span></span>
<span><span class="co">#&gt; [88] farver_2.1.2          memoise_2.0.1         htmltools_0.5.8.1    </span></span>
<span><span class="co">#&gt; [91] lifecycle_1.0.4       mitml_0.4-5           MASS_7.3-65</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="bibliografia" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="bibliografia">Bibliografia</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-benjamin2018redefine" class="csl-entry" role="listitem">
Benjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. <em>Nature Human Behaviour</em>, <em>2</em>(1), 6–10.
</div>
<div id="ref-van2020class" class="csl-entry" role="listitem">
Doorn, J. van, Matzke, D., &amp; Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. <em>Psychology Learning &amp; Teaching</em>, <em>19</em>(1), 36–45.
</div>
<div id="ref-etz2018become" class="csl-entry" role="listitem">
Etz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., &amp; Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. <em>Psychonomic bulletin &amp; review</em>, <em>25</em>(1), 219–234.
</div>
<div id="ref-mehr_melodies" class="csl-entry" role="listitem">
Mehr, S. A., Song, L. A., &amp; Spelke, E. S. (2016). For 5-month-old infants, melodies are social. <em>Psychological Science</em>, <em>27</em>(4), 486–501.
</div>
<div id="ref-schervish2014probability" class="csl-entry" role="listitem">
Schervish, M. J., &amp; DeGroot, M. H. (2014). <em>Probability and statistics</em> (Vol. 563). Pearson Education London, UK:
</div>
<div id="ref-wasserstein2016asa" class="csl-entry" role="listitem">
Wasserstein, R. L., &amp; Lazar, N. A. (2016). The <span>ASA</span>’s statement on p-values: context, process, and purpose. <em>The American Statistician</em>, <em>70</em>(2), 129–133.
</div>
</div>
</section></main><!-- /main --><script>
document.body.classList.add('classic-book');
document.addEventListener('DOMContentLoaded', function() {
  const paragraphs = document.querySelectorAll('p');
  paragraphs.forEach(p => {
    if (p.textContent.length > 200) {
      p.style.hyphens = 'auto';
      p.style.hyphenateCharacter = '-';
    }
  });
  const headings = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
  headings.forEach(h => {
    h.style.fontFeatureSettings = '"liga" 1, "dlig" 1, "smcp" 1';
  });
});
</script><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiato!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiato!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ccaudek\.github\.io\/utet-frequentista\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../../chapters/frequentist_inference/04_sample_size.html" class="pagination-link" aria-label="La grandezza del campione">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">La grandezza del campione</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapters/frequentist_inference/06_two_ind_samples.html" class="pagination-link" aria-label="Test t di Student per campioni indipendenti">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Test t di Student per campioni indipendenti</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p><strong>Inferenza frequentista in psicologia</strong> — Modulo del progetto UTET a supporto del manuale <em>Metodi bayesiani in psicologia</em>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ccaudek/utet-frequentista/blob/main/chapters/frequentist_inference/05_test_ipotesi.qmd" class="toc-action"><i class="bi bi-github"></i>Mostra il codice</a></li><li><a href="https://github.com/ccaudek/utet-frequentista/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Realizzato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>