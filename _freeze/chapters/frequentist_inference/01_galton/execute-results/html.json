{
  "hash": "e953e381c7789b8894d3ca3b026bf7db",
  "result": {
    "engine": "knitr",
    "markdown": "# Inferenza frequentista {#sec-freq-intro}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- Comprendere il background storico da cui si è sviluppato l'approccio frequentista.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere il capitolo *Sampling* di [Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Second Edition)](https://moderndive.com/v2/).\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n## Introduzione\n\nIn questo capitolo esamineremo le radici storiche della statistica **frequentista** e le sue connessioni con il movimento eugenetico. Vedremo come alcune idee sviluppate nel contesto di questa corrente abbiano influenzato l’elaborazione dei metodi statistici che molti di noi utilizzano ancora oggi.\n\n## I Frequentisti sono Razzisti?\n\nNel [@sec-prob-bayes-theorem], abbiamo esplorato le origini storiche e il contesto culturale che hanno portato all’interpretazione del teorema di Bayes proposta da Richard Price. Quelle origini, legate alla rivoluzione americana, rappresentano il “lato luminoso” del liberalismo moderno.\n\nLe origini dell’approccio frequentista, invece, si collocano agli antipodi: sono strettamente intrecciate con ciò che potremmo definire la “parte oscura” della modernità. L’avversione per la soggettività, tipica del frequentismo, riflette una visione più rigida e deterministica, distante dall’apertura e dalla flessibilità del pensiero bayesiano.\n\n### Francis Galton e l’Eugenetica\n\nFrancis Galton (1822-1911), cugino di Charles Darwin, fu un esploratore, un medico e un pioniere della meteorologia. Ma il suo contributo più importante, e anche più controverso, riguardò la statistica e lo studio dell’ereditarietà del talento. \n\n- **Distribuzione Normale e Regressione**  \n  Galton formalizzò la distribuzione normale e introdusse il concetto di “regressione verso la media”, chiamata inizialmente “regressione verso la mediocrità”.  \n- **Hereditary Genius**  \n  Nel suo libro *Hereditary Genius*, Galton sosteneva che il talento fosse trasmesso all’interno di specifiche famiglie. Fu lui a coniare la famosa espressione “nature and nurture” per indicare il ruolo combinato di eredità e ambiente nello sviluppo umano.  \n- **Eugenetica**  \n  Galton mirava a “migliorare la specie umana” promuovendo la riproduzione tra famiglie ritenute “di successo” e scoraggiandola tra quelle considerate “inferiori”. Le sue idee, fortemente razziste, includevano l’idea che gli africani fossero “inferiori” e “pigri”, gli arabi “semplici consumatori della produzione altrui” e che gli anglosassoni fossero la “razza superiore”.\n\n### L’Impatto di Galton su Pearson e Fisher\n\nLe teorie di Galton influenzarono Karl Pearson (1857-1936) e Ronald Fisher (1890-1962), due figure chiave della statistica moderna. Entrambi condividevano idee razziste e appoggiavano l’eugenetica:\n\n- **Karl Pearson**  \n  Professore all’University College di Londra, sviluppò strumenti come il test del chi quadrato e la deviazione standard. Ereditò la cattedra di eugenetica fondata da Galton.  \n- **Ronald Fisher**  \n  Considerato uno dei padri della statistica moderna, sviluppò l’analisi della varianza (ANOVA), il concetto di significatività statistica e il metodo della massima verosimiglianza (MLE). \n\nQuesti autori cercarono di allontanare la statistica dalla prospettiva di Laplace e Bayes, rifiutando l’idea di introdurre componenti soggettive nella loro “scienza”. Volevano che la statistica apparisse del tutto “oggettiva” per sostenere teorie eugenetiche e gerarchie razziali come se fossero dimostrate scientificamente.\n\n## Implicazioni per le Pratiche Correnti\n\nIn che misura dovremmo considerare le implicazioni storiche ed etiche del frequentismo quando lo utilizziamo oggi? Secondo [@chivers2024everything], sebbene sia evidente che l’ideologia razziale nazista possa essere collegata alle idee di Galton, la questione centrale in statistica rimane: **“Quale approccio è metodologicamente corretto?”** o, più pragmaticamente, **“Quale approccio è più utile?”**.\n\nTuttavia, limitarsi a un dibattito puramente metodologico rischia di trascurare il fatto che la scienza non si svolge in una “torre d’avorio” astratta, ma ha conseguenze concrete. Se una teoria A, pur essendo efficace in uno scenario ideale, ha effetti profondamente negativi nella realtà, dovremmo davvero adottarla acriticamente? La risposta, per molti, è **no**.\n\nNel caso del frequentismo, non solo emergono questioni etiche, ma – come vedremo in seguito – si evidenziano anche **limiti metodologici**. La sua pretesa di “oggettività” si rivela un’illusione quando si analizza in profondità il funzionamento reale delle procedure inferenziali. In psicologia, dove la variabilità individuale e le questioni etiche sono centrali, questi difetti possono avere conseguenze particolarmente dannose.\n\n::: {.callout-important}\n**Nota didattica:** L’approccio frequentista viene presentato qui soprattutto per mostrare perché il suo uso esclusivo sia problematico. In questo capitolo descriveremo i fondamenti statistici del frequentismo e la logica delle sue procedure inferenziali. Nel capitoli successivi discuteremo invece come le sue applicazioni pratiche possano ostacolare il progresso della psicologia.\n:::\n\n## Il Paradigma Frequentista\n\nL’obiettivo della statistica frequentista è trarre conclusioni su un’intera **popolazione** partendo da un **campione** di dati. In questo contesto:\n\n- I dati osservati vengono considerati come un’estrazione casuale (un “campione”) da una popolazione più ampia.  \n- Il modello statistico assume che esista un processo generatore dei dati, descritto da una distribuzione di probabilità.  \n- Quando raccogliamo un campione di dati, dobbiamo tenere presente che avremmo potuto ottenere molti altri campioni diversi (il principio di **ripetizione del campionamento**).  \n\n### Probabilità e Ripetizione del Campionamento\n\nIl frequentismo adotta un’interpretazione della probabilità basata sulle **frequenze**: se ripetessimo un esperimento moltissime volte, la probabilità di un evento sarebbe il rapporto tra il numero di volte in cui l’evento si verifica e il numero totale di prove.\n\n### Stima di un Parametro\n\nSupponiamo di voler stimare un parametro (ad esempio, la media di una popolazione). Il frequentismo cerca un **stimatore** – una funzione del campione – che abbia determinate proprietà, tra cui l’assenza di distorsione (l’**unbiasedness**) e la **consistenza** (la vicinanza alla realtà con l’aumentare del numero di dati).\n\nUn esempio comune è la stima della media della popolazione tramite la media del campione. Sotto certe condizioni, si può dimostrare che, ripetendo l’esperimento moltissime volte, la media del campione in media coinciderà con la vera media della popolazione.\n\n### Intervalli di Confidenza\n\nNell’approccio frequentista, invece di fornire un singolo valore come stima di un parametro, si costruisce un **intervallo di confidenza**. L’idea fondamentale è che, se ripetessimo molte volte la stessa procedura di campionamento e di calcolo dell’intervallo, una certa percentuale di questi (ad esempio il 95%) conterrà effettivamente il valore vero del parametro. \n\nPrima di raccogliere i dati, gli estremi di questo intervallo (i “limiti di confidenza”) sono **variabili casuali**, perché dipendono dal campione che otterremo. Di conseguenza, la probabilità (per esempio, il 95%) si riferisce alla **procedura** di costruzione dell’intervallo, non all’intervallo in sé dopo l’osservazione dei dati. Una volta infatti che il campione è stato raccolto e l’intervallo è stato calcolato, quest’ultimo è un oggetto “fisso”: **o** contiene il valore vero del parametro, **o** non lo contiene; non è più possibile attribuirgli una probabilità di contenere il parametro. L’affermazione “intervallo di confidenza al 95%” significa dunque che, **sul lungo periodo**, usando sempre la stessa procedura, il 95% degli intervalli costruiti conterrà il parametro vero.\n\n### Test delle Ipotesi: Approccio Frequentista e Limitazioni\n\nNel contesto del test di un’ipotesi (ad esempio, $H_0$: “la media di una popolazione è uguale a 0”), l’approccio frequentista definisce una **regione di rifiuto** in base a un livello di significatività prefissato (ad esempio, $\\alpha = 0.05$). Se il risultato dell’analisi (come il p-value) cade all’interno di questa regione, si procede a **rifiutare** $H_0$; altrimenti, si **manca di rifiutare** $H_0$ (ovvero, non si rifiuta l’ipotesi nulla).\n\n- **Errore di tipo I** (falso positivo): si verifica quando si rifiuta $H_0$ nonostante essa sia vera.  \n- **Errore di tipo II** (falso negativo): si verifica quando non si rifiuta $H_0$ nonostante essa sia falsa.  \n\nNel paradigma frequentista, il ricercatore controlla la probabilità di questi errori, in particolare l’errore di tipo I, attraverso la scelta di $\\alpha$ e il calcolo di indicatori come il p-value. Tuttavia, **questo approccio presenta alcune criticità**:\n\n1. **Decisione dicotomica**  \n   Il test conduce a una scelta binaria (rifiutare o non rifiutare $H_0$), che può risultare eccessivamente rigida. I fenomeni reali spesso non si prestano a una categorizzazione netta basata su una soglia arbitraria, rendendo la distinzione “significativo/non significativo” potenzialmente fuorviante. Una visione più sfumata, che consideri l’entità dell’effetto e l’incertezza, potrebbe essere più informativa.\n\n2. **Soglia arbitraria**  \n   Il valore di $\\alpha$ (comunemente fissato a 0.05) è in gran parte una convenzione. Ad esempio, un valore-p di 0.049 porta al rifiuto di $H_0$, mentre un valore-p di 0.051 non lo fa, nonostante la differenza tra i due casi sia minima. Questa arbitrarietà può influenzare in modo significativo l’interpretazione dei risultati, creando una discontinuità artificiale.\n\n3. **Nessuna prova diretta di verità/falsità**  \n   Un valore-p basso non implica che $H_0$ sia “falsa” o che un’ipotesi alternativa sia “vera”. Indica semplicemente che, **assumendo** $H_0$ vera, dati simili (o più estremi) sarebbero rari sotto ripetuti campionamenti. Il test frequentista non fornisce una risposta alla domanda “Qual è la probabilità che $H_0$ sia vera?”, limitando la sua capacità di supportare inferenze dirette sulla veridicità delle ipotesi.\n\nQueste criticità evidenziano come la rigidità del test (basato su una decisione binaria) e l’uso di soglie fisse possano risultare problematici, specialmente in discipline come la psicologia, dove le misurazioni sono spesso affette da rumore e le differenze tra condizioni possono essere sottili. Un approccio più flessibile, che integri la stima degli effetti, gli intervalli di confidenza e una valutazione contestuale, potrebbe offrire una comprensione più robusta e sfumata dei dati.\n\n## Riflessioni Conclusive\n\nIn questo capitolo abbiamo mostrato come la statistica frequentista, pur essendo stata un pilastro dell’inferenza moderna, affondi le proprie radici in idee profondamente problematiche, come l’eugenetica e il razzismo sostenuti da Galton, Pearson e Fisher. Sebbene oggi queste teorie sembrino superate e distanti dalle nostre pratiche di laboratorio, conoscerne la genesi aiuta a comprendere come l’idea di un’**oggettività assoluta** sia stata impiegata per legittimare visioni ideologiche discutibili.\n\nParallelamente, la riflessione storica solleva interrogativi sul **metodo** e sulle sue **implicazioni pratiche**. La metafora della “torre d’avorio” mostra quanto sia pericoloso trattare la scienza come un sistema chiuso, ignorando le conseguenze etiche e sociali. Nel campo della psicologia, in particolare, la crisi di replicabilità [@McElreath_rethinking] rivela come l’uso acritico di procedure frequentiste possa influire sulla validità dei risultati.\n\nIn definitiva, il frequentismo non va considerato solo come un insieme di tecniche, ma come un paradigma con implicazioni culturali, etiche e metodologiche. Nel prossimo capitolo mostreremo come le applicazioni pratiche dell’approccio frequentista possano risultare limitanti e, talvolta, dannose per il progresso della psicologia [@gelman1995bayesian]. Conoscere le basi e le implicazioni di tale paradigma è il primo passo per un uso più consapevole e responsabile degli strumenti statistici.\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#> [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#> [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#> [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#> [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#> [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#> [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#> [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#> [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#> [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#> [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#> [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#> [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#> [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#> [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#> [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#> [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#> [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#> [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#> [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#> [76] pkgconfig_2.0.3\n```\n:::\n\n\n## Bibliografia {.unnumbered}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}