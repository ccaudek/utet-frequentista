{
  "hash": "467de6caf7c811fbe03397cf2d0b0645",
  "result": {
    "engine": "knitr",
    "markdown": "# La grandezza del campione {#sec-frequentist-sample-size}\n\n::: callout-important\n## In questo capitolo imparerai a\n\n- calcolare la grandezza del campione, dato un margine prefissato di errore.\n:::\n\n::: callout-tip\n## Prerequisiti\n\n- Leggere l'articolo *Power to detect what? Considerations for planning and evaluating sample size* [@giner2024power].\n:::\n\n::: callout-caution\n## Preparazione del Notebook\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhere::here(\"code\", \"_common.R\") |> \n  source()\n```\n:::\n\n:::\n\n\n## Introduzione\n\nLa scelta della dimensione del campione è fondamentale per garantire che i risultati di uno studio siano affidabili, bilanciando precisione e costi. In questo capitolo, esamineremo come calcolare la dimensione minima del campione necessaria per stimare la **media di una popolazione** con un margine di errore prefissato e un determinato livello di confidenza. Utilizzeremo un esempio tratto dalla psicologia per illustrare il processo e fornire implementazioni pratiche in R.\n\n## La Logica Dietro la Scelta della Dimensione Campionaria\n\nIn psicologia, è comune stimare la media di una variabile (ad esempio, il punteggio medio di una scala psicometrica). I vantaggi di utilizzare campioni più grandi includono:\n\n- **Stime più precise:** Con un campione più grande, la varianza dell'estimatore diminuisce, rendendo le stime più accurate.\n- **Maggiore fiducia nei risultati:** Un campione più grande riduce il margine di errore, aumentando la certezza dei risultati.\n\nTuttavia, i campioni più grandi richiedono risorse maggiori in termini di tempo e denaro. Pertanto, il problema si riduce spesso a trovare il **campione più piccolo che garantisca la precisione desiderata**.\n\n## Calcolo della Dimensione Campionaria\n\nPer campioni sufficientemente grandi, la media campionaria $\\bar{X}$ segue una distribuzione normale:\n\n$$\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right),\n$$\n\ndove:\n\n- $n$ è la dimensione del campione,\n- $\\mu$ è la vera media della popolazione,\n- $\\sigma^2$ è la varianza della popolazione.\n\nIl nostro obiettivo è trovare la dimensione campionaria $n$ tale che:\n\n$$\nP\\left(|\\bar{X} - \\mu| < E\\right) \\geq 0.95,\n$$\n\ndove:\n\n- $\\bar{X}$ è la media campionaria,\n- $\\mu$ è la media della popolazione,\n- $E$ è il margine di errore massimo accettabile.\n\nSappiamo che, per il **teorema centrale del limite**, la media campionaria $\\bar{X}$ può essere standardizzata come segue:\n\n$$\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}.\n$$\n\nQuesta quantità $Z$ segue una distribuzione normale standard $\\mathcal{N}(0, 1)$.\n\nQuindi, possiamo riscrivere la probabilità richiesta come:\n\n$$\nP\\left(|\\bar{X} - \\mu| < E\\right) = P\\left(|Z| < z_{0.025}\\right),\n$$\n\ndove $z_{0.025} = 1.96$ è il quantile superiore della distribuzione normale standard corrispondente a un livello di confidenza del $95\\%$.\n\nDalla definizione della variabile standardizzata $Z$, possiamo ricavare la relazione per il margine di errore:\n\n$$\n|\\bar{X} - \\mu| < E \\implies Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\implies \\left|\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\\right| < \\frac{E}{\\sigma / \\sqrt{n}}.\n$$\n\nSostituendo la condizione $|Z| < z_{0.025}$, otteniamo:\n\n$$\n\\frac{E}{\\sigma / \\sqrt{n}} = z_{0.025}.\n$$\n\nRisolvendo per $\\sqrt{n}$, moltiplichiamo entrambi i membri per $\\sigma / \\sqrt{n}$:\n\n$$\nE = z_{0.025} \\cdot \\frac{\\sigma}{\\sqrt{n}}.\n$$\n\nIsoliamo $\\sqrt{n}$ dividendo entrambi i membri per $z_{0.025} \\cdot \\sigma$:\n\n$$\n\\sqrt{n} = \\frac{z_{0.025} \\cdot \\sigma}{E}.\n$$\n\nInfine, eleviamo entrambi i membri al quadrato per ottenere $n$:\n\n$$\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n$$\n\nIn conclusione, la dimensione campionaria minima $n$ necessaria per soddisfare il margine di errore $E$ e il livello di confidenza richiesto è:\n\n$$\nn = \\left(\\frac{z_{0.025} \\cdot \\sigma}{E}\\right)^2.\n$$\n\n## Stima della Media del Punteggio di Autostima\n\nConsideriamo un esempio pratico: vogliamo stimare la media del punteggio di autostima in una popolazione di giovani adulti, utilizzando la *Rosenberg Self-Esteem Scale* (RSES), che assegna un punteggio compreso tra 0 e 30.\n\nDettagli del Problema:\n\n- Deviazione standard del punteggio: $\\sigma = 6$ (stimata da studi precedenti).\n- Margine di errore massimo accettabile: $E = 2$.\n- Livello di confidenza: $95\\%$.\n\nImplementiamo in R la formula derivata in precedenza.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Parametri del problema\nsigma <- 6     # Deviazione standard del punteggio RSES\nE <- 2         # Margine di errore desiderato\nz_alpha <- qnorm(0.975)  # Quantile superiore della distribuzione normale (95% confidenza)\n\n# Calcolo della dimensione campionaria\nn <- (z_alpha * sigma / E)^2\nn <- ceiling(n)  # Arrotondamento all'intero successivo\nn\n#> [1] 35\n```\n:::\n\n\nIn conclusione, la dimensione campionaria minima necessaria per stimare la media del punteggio di autostima con un margine di errore massimo di 2 punti e un livello di confidenza del 95% è $n = 35$.\n\n### Approfondimenti\n\n1. **Precisione e Livello di Confidenza**\n   Aumentando $n$, la varianza di $\\bar{X}$ diminuisce:\n   \n   $$\n   \\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}.\n   $$\n   \n   Questo restringe l'intervallo di confidenza e migliora la precisione.\n\n2. **Costo e Praticità**\n   Un campione più grande comporta costi più elevati. È importante trovare il giusto compromesso tra precisione e fattibilità.\n\n3. **Adattamento ad Altri Livelli di Confidenza**\n   Per altri livelli di confidenza, basta modificare il quantile $z_{\\alpha/2}$. Ad esempio, per un livello di confidenza del 99%, $z_{0.005} \\approx$ 2.576.\n\n## Riflessioni Conclusive\n\nDefinire la dimensione del campione rappresenta un passaggio cruciale nella progettazione di qualsiasi studio psicologico. Un approccio matematico rigoroso, fondato su analisi di potenza statistica e stime di effetti attesi, consente di ottimizzare il bilanciamento tra precisione dei risultati e limitazioni pratiche, come tempi, costi e disponibilità dei partecipanti. Questo equilibrio è fondamentale per garantire che i dati raccolti siano sufficientemente robusti da supportare conclusioni valide, senza tuttavia sprecare risorse in campioni eccessivamente ampi. Una corretta determinazione del campione contribuisce inoltre a ridurre il rischio di errori di tipo I e II, rafforzando l'integrità scientifica della ricerca.\n\nNel confronto tra paradigmi statistici, l'approccio frequentista si distingue per la sua enfasi sul controllo degli errori e sulla replicabilità attraverso il calcolo del valore *p* e della potenza statistica. Questo metodo richiede una rigorosa pianificazione preliminare, con la determinazione a priori della dimensione del campione basata su stime dell'effetto atteso e soglie prefissate di significatività e potenza. Tale rigidità metodologica, sebbene garantisca standardizzazione e controllo degli errori di Tipo I, può presentare notevoli limitazioni. In particolare, non permette modifiche alla dimensione del campione durante lo studio senza compromettere la validità statistica e può portare al problema dello \"optional stopping\", dove il controllo ripetuto dei risultati aumenta il rischio di falsi positivi.\n\nL'approccio bayesiano, d'altra parte, offre una prospettiva complementare, ponendo l'accento sulla stima e sull'aggiornamento delle credenze in base ai dati osservati. Nel contesto bayesiano, la dimensione del campione non è solo uno strumento per garantire la significatività statistica, ma diventa un mezzo per affinare la precisione delle stime a posteriori. Questo approccio si caratterizza per una maggiore flessibilità, permettendo il monitoraggio continuo dell'evidenza attraverso i fattori di Bayes e l'aggiornamento sequenziale delle stime di probabilità. L'uso di distribuzioni a priori consente di incorporare conoscenze pregresse, portando a distribuzioni a posteriori che quantificano l'incertezza in modo più intuitivo e direttamente interpretabile.\n\nLa scelta di quando interrompere la raccolta dati rappresenta un esempio emblematico delle differenze tra i due approcci. Mentre il metodo frequentista richiede una dimensione campionaria fissa determinata a priori, l'approccio bayesiano permette una maggiore flessibilità, consentendo di interrompere la raccolta quando si raggiunge un livello desiderato di precisione nelle stime posteriori. Tuttavia, questa flessibilità comporta anche sfide specifiche, come la necessità di specificare distribuzioni a priori appropriate e una maggiore complessità computazionale.\n\nUna soluzione pragmatica potrebbe essere l'integrazione dei punti di forza di entrambi gli approcci. Si potrebbe utilizzare l'analisi della potenza frequentista per stabilire una dimensione minima del campione, implementando poi un monitoraggio bayesiano per valutare quando l'evidenza raccolta è sufficiente. Questo approccio integrato dovrebbe essere guidato da regole decisionali stabilite a priori e supportato da analisi di sensitività per valutare la robustezza delle conclusioni.\n\nIn sintesi, la scelta della dimensione del campione e la decisione su quando concludere la raccolta dati non dovrebbero essere viste solo come problemi tecnici, ma come opportunità per riflettere sulle priorità della ricerca, sul contesto teorico e sulle metodologie più adatte. La combinazione dei punti di forza degli approcci frequentista e bayesiano può portare a una ricerca più robusta, flessibile e informativa, contribuendo a un progresso scientifico più solido e sfaccettato. Tale scelta metodologica deve considerare gli obiettivi specifici dello studio, le risorse disponibili, i requisiti delle riviste scientifiche e la natura delle ipotesi da testare, bilanciando le esigenze di precisione con quelle di praticabilità. Pertanto, investire tempo nella pianificazione di questo aspetto non è solo una scelta metodologica, ma un imperativo etico per chiunque si impegni nella produzione di conoscenza psicologica.\n\n## Esercizi {.unnumbered}\n\n::: {.callout-important title=\"Problemi 1\" collapse=\"true\"}\n\n**Esercizio 1: Dimensione del campione per un margine di errore prefissato**\n\n1. Esaminando i dati raccolti, hai ottenuto una **deviazione standard campionaria** (stimata) $s \\approx 4{,}3$ sui punteggi SWLS.  \n2. Hai stabilito di voler **stimare la media SWLS** con un **margine di errore massimo** $E = 2$ punti e un livello di confidenza del 95%.  \n3. Utilizzando il valore critico $z_{0.025} \\approx 1{,}96$ (per il 95%), ipotizza che la **deviazione standard di popolazione** $\\sigma$ possa essere approssimata da $s$. Calcola quindi la dimensione del campione $n$ necessaria:\n\n   $$\n   n = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2.\n   $$\n\n4. **Interpreta** il risultato: è un campione grande o piccolo? Quali fattori potrebbero influenzarne la validità (ad es. la stima di $\\sigma$ da soli 10 soggetti)?\n\n**Esercizio 2: Aumento del livello di confidenza e influenza su $n$**\n\n1. Con gli stessi dati dell’Esercizio 1 (stesso $\\sigma\\approx4{,}3$, stesso $E=2$), calcola la dimensione $n$ se volessi un **livello di confidenza del 99%**.  \n2. Confronta tale dimensione con quella trovata al 95%.  \n3. Commenta: perché un livello di confidenza più elevato richiede un campione più grande? E in che modo ciò può impattare sull’**organizzazione pratica** della ricerca (tempi, costi, disponibilità di partecipanti)?\n\n**Esercizio 3: Potere statistico per rilevare una differenza dalla media di riferimento**\n\n1. Ipotizza che la **media SWLS** di riferimento (ad es. in letteratura) sia 24.  \n2. Vuoi un test a **una coda** (one-sample t-test o z-test) con $\\alpha = 0{,}05$, e desideri un **potere** ($1-\\beta$) dell’80% di rivelare una **differenza** di 3 punti (cioè vuoi essere in grado di concludere che la vera media è *almeno* 3 punti più alta o più bassa di 24).  \n3. Usa come stima della **deviazione standard** la stessa $s \\approx 4{,}3$. Sulla base delle formule di potenza statistica per un test a una coda, calcola un **numero approssimativo di soggetti** $n$ necessari. *(Suggerimento: puoi usare formule di power analysis o fare riferimento a software R, es. `power.t.test()` o `pwr.t.test()`.)*  \n4. **Interpreta** la dimensione campionaria trovata: è realistica per un esperimento in cui potresti raccogliere partecipanti simili a quelli del pilot? Oppure rappresenta un valore troppo elevato?\n\n**Esercizio 4: Confronto tra due gruppi e potere statistico**\n\n1. Ipotizza di voler confrontare **due gruppi** indipendenti (ognuno con punteggi SWLS) e di voler rilevare una differenza media di **5 punti** tra i due gruppi (Gruppo A vs Gruppo B).  \n2. Assumi che ciascun gruppo abbia la **stessa deviazione standard** $\\sigma = 4{,}3$.  \n3. Vuoi un test a due code, $\\alpha=0{,}05$, e un potere dell’80%. Utilizza (se vuoi) la formula approssimata per due campioni indipendenti, oppure uno **strumento in R** (ad es. `power.t.test` con `type=\"two.sample\"`).  \n4. Calcola (o stima) la dimensione $n$ per **ciascun gruppo**.  \n5. **Commenta**: confronta il risultato con la disponibilità realistica dei partecipanti. Che implicazioni metodologiche o pratiche emergono?\n:::\n\n::: {.callout-tip title=\"Soluzioni 1\" collapse=\"true\"}\n**Soluzione Esercizio 1**\n\n**Dati principali**:  \n- $\\sigma \\approx 4{,}3$ (stimata dal pilot)  \n- $E = 2$ (margine di errore)  \n- Livello di confidenza 95% $\\Rightarrow z_{\\alpha/2} \\approx 1{,}96$\n\nLa **formula** per la dimensione campionaria:\n\n$$\nn = \\left(\\frac{z_{\\alpha/2} \\times \\sigma}{E}\\right)^2 \n$$\n\n**Calcolo**:\n\n$$\nn \n= \\left(\\frac{1{,}96 \\times 4{,}3}{2}\\right)^2 \n= \\left(\\frac{8{,}428}{2}\\right)^2\n= (4{,}214)^2\n\\approx 17{,}76.\n$$\n\nArrotondando all’intero **superiore**:\n\n$$\nn \\approx 18.\n$$\n\n**Interpretazione**  \n\n- Servirebbero circa **18 partecipanti** (anziché 10) per ottenere un IC al 95% con margine d’errore 2, ipotizzando $\\sigma \\approx 4{,}3$.  \n- **Limiti**: la $\\sigma$ deriva da un campione di sole 10 persone e potrebbe non rappresentare bene la **deviazione standard reale** dell’intera popolazione. Se in realtà $\\sigma$ fosse più grande, $n$ andrebbe rivisto al rialzo; se fosse minore, 18 potrebbe essere anche sovrastimato.  \n- 18 non è troppo elevato; potrebbe essere gestibile in uno studio con costi contenuti. Tuttavia, la validità dipende dalla solidità della stima di $\\sigma$.\n\n**Soluzione Esercizio 2**\n\n**Cambio di livello di confidenza**: da 95% a 99%. Ora $\\alpha=0{,}01$ e $\\alpha/2=0{,}005$.  \nIl valore critico $z_{0.005}$ è circa **2,576**.\n\n$$\nn = \\left(\\frac{2,576 \\times 4{,}3}{2}\\right)^2\n= \\left(\\frac{11{,}0768}{2}\\right)^2\n= (5{,}5384)^2\n\\approx 30{,}7.\n$$\n\nArrotondato in **eccesso**:\n\n$$\nn \\approx 31.\n$$\n\n**Confronto con i 18 trovati prima**  \n- Aumentando la confidenza dal 95% al 99%, la dimensione campionaria passa da ~18 a ~31, cioè un incremento notevole.  \n- **Motivo**: per assicurare un intervallo che, nel lungo periodo, includa il vero valore nel 99% dei casi, occorre un margine di errore più “tollerante” (oppure un campione più grande per mantenere lo stesso $E$).  \n- **Impatto pratico**: reclutare 31 soggetti (invece di 18) può pesare in termini di costi e disponibilità, ma riduce l’incertezza dell’IC dal punto di vista frequentista.\n\n**Soluzione Esercizio 3**\n\n**Potere statistico (80%) per rilevare $\\Delta = 3$** in un test a **una coda** contro il valore di riferimento 24.  \n- $\\alpha=0{,}05$ (quindi **una coda**, il valore critico si situa intorno a **z=1.645** per la potenza, ma i calcoli precisi si fanno di solito con formule di power analysis).  \n- $\\sigma \\approx 4{,}3$.  \n- $\\Delta = 3$.\n\nIn R, con `pwr.t.test()` o `power.t.test()`, l’approssimazione verrebbe impostata come:\n\n```r\nlibrary(pwr)  # se usi pwr\npwr.t.test(d = 3/4.3, sig.level = 0.05, power = 0.80,\n           type = \"one.sample\", alternative=\"greater\")\n```\noppure:\n\n```r\npower.t.test(delta = 3, sd = 4.3, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\", \n             alternative = \"one.sided\")\n```\n\n**Esempio di risultato** (numeri indicativi): potresti ottenere $n \\approx 20$. *(Il valore preciso cambia a seconda delle approssimazioni e del software.)*\n\n**Interpretazione**  \n- Con 20 soggetti, se $\\Delta$ fosse veramente di 3 punti rispetto a 24, il test a una coda dovrebbe avere l’80% di chance di rigettare l’ipotesi nulla (cioè di rilevare la differenza) a $\\alpha=0{,}05$.  \n- Se cercassi di replicare il pilot (dove avevi 10 soggetti), probabilmente la potenza sarebbe inferiore.  \n- Potresti chiederti se 20 partecipanti siano facili da reclutare o se, dal punto di vista pratico, 20 restino pochi per altre ragioni (ad es. robustezza dei modelli, normalità, outlier).\n\n**Soluzione Esercizio 4**\n\na) Due campioni indipendenti, differenza attesa = 5 punti, potere = 80%, test a due code\n\nCon formula approssimata (oppure software R), i parametri tipici:\n\n- **Differenza minima rilevabile**: $\\Delta = 5$  \n- $\\sigma = 4{,}3$ in ciascun gruppo  \n- $\\alpha = 0{,}05$ (due code), potere = 80%  \n- Tipo di test: “two-sample t test” (Gruppo A vs Gruppo B, varianze uguali)\n\nIn R con `power.t.test()`:\n\n```r\npower.t.test(delta = 5, sd = 4.3, sig.level = 0.05,\n             power = 0.80, type = \"two.sample\",\n             alternative = \"two.sided\")\n```\n\n**Esempio di risultato**: potresti ottenere $n \\approx 14$ per gruppo (quindi **28** totali). *(Il numero può variare leggermente a seconda delle approssimazioni.)*\n\nb) Commento\n\n- **18** o **20** partecipanti totali potrebbero bastare per un one-sample test (Esercizi 1–3), ma qui **servono 28** (14 per gruppo) per avere lo stesso potere su una differenza di 5 punti.  \n- In **pratica**:  \n  - Se hai risorse per arruolare solo 15–20 persone totali, potrebbe non esserci potere sufficiente (grande rischio di errore di tipo II).  \n  - Potrebbe convenire ridurre la differenza minima desiderata (ma questo cambierebbe le conclusioni) o cercare un campione più grande.  \n- Le **considerazioni metodologiche** includono: “Posso davvero aspettarmi 5 punti di differenza?” Se la differenza reale fosse più piccola, servirebbe un campione ancora più grande per rilevarla con sufficiente potenza.\n\n**Conclusioni Finali**\n\n- La **dimensione del campione** dipende da molti fattori:  \n  1. Varianza (o deviazione standard) stimata.  \n  2. Margine di errore desiderato (o differenza minima rilevabile).  \n  3. Livello di confidenza o $\\alpha$.  \n  4. Potere statistico $(1-\\beta)$.  \n- I dati **SWLS** di un pilot di 10 persone forniscono **un’indicazione** iniziale (stima di $\\sigma$), ma la precisione di quella stima è limitata.  \n- Per studi sperimentali o correlazionali, i calcoli di dimensione campionaria andrebbero fatti **a priori** (idealmente ancor prima di raccogliere i dati) e basati su stime realistiche o su letteratura pre-esistente.  \n- Se la stima di $\\sigma$ o della dimensione dell’effetto $\\Delta$ è incerta, è utile svolgere **analisi di sensitività**, variando gli input per vedere come cambiano i risultati.\n:::\n\n## Informazioni sull'Ambiente di Sviluppo {.unnumbered} \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsessionInfo()\n#> R version 4.5.1 (2025-06-13)\n#> Platform: aarch64-apple-darwin20\n#> Running under: macOS Sequoia 15.6.1\n#> \n#> Matrix products: default\n#> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \n#> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n#> \n#> locale:\n#> [1] C/UTF-8/C/C/C/C\n#> \n#> time zone: Europe/Rome\n#> tzcode source: internal\n#> \n#> attached base packages:\n#> [1] stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] pillar_1.11.0         tinytable_0.13.0      patchwork_1.3.2      \n#>  [4] ggdist_3.3.3          tidybayes_3.0.7       bayesplot_1.14.0     \n#>  [7] ggplot2_3.5.2         reliabilitydiag_0.2.1 priorsense_1.1.1     \n#> [10] posterior_1.6.1       loo_2.8.0             rstan_2.32.7         \n#> [13] StanHeaders_2.32.10   brms_2.22.0           Rcpp_1.1.0           \n#> [16] sessioninfo_1.2.3     conflicted_1.2.0      janitor_2.2.1        \n#> [19] matrixStats_1.5.0     modelr_0.1.11         tibble_3.3.0         \n#> [22] dplyr_1.1.4           tidyr_1.3.1           rio_1.2.3            \n#> [25] here_1.0.1           \n#> \n#> loaded via a namespace (and not attached):\n#>  [1] svUnit_1.0.8          tidyselect_1.2.1      farver_2.1.2         \n#>  [4] fastmap_1.2.0         TH.data_1.1-4         tensorA_0.36.2.1     \n#>  [7] digest_0.6.37         timechange_0.3.0      estimability_1.5.1   \n#> [10] lifecycle_1.0.4       survival_3.8-3        magrittr_2.0.3       \n#> [13] compiler_4.5.1        rlang_1.1.6           tools_4.5.1          \n#> [16] knitr_1.50            bridgesampling_1.1-2  htmlwidgets_1.6.4    \n#> [19] curl_7.0.0            pkgbuild_1.4.8        RColorBrewer_1.1-3   \n#> [22] abind_1.4-8           multcomp_1.4-28       withr_3.0.2          \n#> [25] purrr_1.1.0           grid_4.5.1            stats4_4.5.1         \n#> [28] colorspace_2.1-1      xtable_1.8-4          inline_0.3.21        \n#> [31] emmeans_1.11.2-8      scales_1.4.0          MASS_7.3-65          \n#> [34] cli_3.6.5             mvtnorm_1.3-3         rmarkdown_2.29       \n#> [37] ragg_1.5.0            generics_0.1.4        RcppParallel_5.1.11-1\n#> [40] cachem_1.1.0          stringr_1.5.1         splines_4.5.1        \n#> [43] parallel_4.5.1        vctrs_0.6.5           V8_7.0.0             \n#> [46] Matrix_1.7-4          sandwich_3.1-1        jsonlite_2.0.0       \n#> [49] arrayhelpers_1.1-0    systemfonts_1.2.3     glue_1.8.0           \n#> [52] codetools_0.2-20      distributional_0.5.0  lubridate_1.9.4      \n#> [55] stringi_1.8.7         gtable_0.3.6          QuickJSR_1.8.0       \n#> [58] htmltools_0.5.8.1     Brobdingnag_1.2-9     R6_2.6.1             \n#> [61] textshaping_1.0.3     rprojroot_2.1.1       evaluate_1.0.5       \n#> [64] lattice_0.22-7        backports_1.5.0       memoise_2.0.1        \n#> [67] broom_1.0.9           snakecase_0.11.1      rstantools_2.5.0     \n#> [70] coda_0.19-4.1         gridExtra_2.3         nlme_3.1-168         \n#> [73] checkmate_2.3.3       xfun_0.53             zoo_1.8-14           \n#> [76] pkgconfig_2.0.3\n```\n:::\n\n\n## Bibliografia {.unnumbered}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}